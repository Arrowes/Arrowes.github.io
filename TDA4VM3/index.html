<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/128.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/16.png">
  <link rel="mask-icon" href="/images/arrow.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wangyujie.space","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"default"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":true,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="以目标检测算法YOLOX为例，记录模型从权重文件转换为ONNX，再使用TIDL(Importer&#x2F;Tools)编译为可执行文件，最后于SK板运行及评估的开发流程。">
<meta property="og:type" content="article">
<meta property="og:title" content="TDA4③：YOLOX的模型转换与SK板端运行">
<meta property="og:url" content="https://wangyujie.space/TDA4VM3/index.html">
<meta property="og:site_name" content="Arrow的笔记本">
<meta property="og:description" content="以目标检测算法YOLOX为例，记录模型从权重文件转换为ONNX，再使用TIDL(Importer&#x2F;Tools)编译为可执行文件，最后于SK板运行及评估的开发流程。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://github.com/TexasInstruments/edgeai-yolox/raw/main/yolox/utils/figures/Focus.png">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/TDA4VM3onnxinference.jpg">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/TDA4VM3sdktidlyolox.png">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/TDA4VM3studioyolox.png">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/TDA4VM3yoloxs.png">
<meta property="og:image" content="https://software-dl.ti.com/jacinto7/esd/processor-sdk-linux-sk-tda4vm/latest/exports/docs/_images/perf_plots.png">
<meta property="article:published_time" content="2023-06-15T01:40:00.000Z">
<meta property="article:modified_time" content="2024-12-03T14:51:22.462Z">
<meta property="article:author" content="Arrow">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="嵌入式">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/TexasInstruments/edgeai-yolox/raw/main/yolox/utils/figures/Focus.png">

<link rel="canonical" href="https://wangyujie.space/TDA4VM3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>TDA4③：YOLOX的模型转换与SK板端运行 | Arrow的笔记本</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Arrow的笔记本" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Arrow的笔记本</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <a>
        <img class="custom-logo-image" src="/images/arrow.png" alt="Arrow的笔记本">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="https://wangyujie.space/pintree/" rel="section"><i class="fa fa-sitemap fa-fw"></i>书签</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wangyujie.space/TDA4VM3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Arrow">
      <meta itemprop="description" content="记录一些杂七杂八的东西">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Arrow的笔记本">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          TDA4③：YOLOX的模型转换与SK板端运行
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-06-15 09:40:00" itemprop="dateCreated datePublished" datetime="2023-06-15T09:40:00+08:00">2023-06-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-12-03 22:51:22" itemprop="dateModified" datetime="2024-12-03T22:51:22+08:00">2024-12-03</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>15 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>以目标检测算法YOLOX为例，记录模型从权重文件转换为ONNX，再使用TIDL(Importer&#x2F;Tools)编译为可执行文件，最后于SK板运行及评估的开发流程。</p>
<span id="more"></span>

<p>接上一篇：<a href="https://wangyujie.space/TDA4VM2/">TDA4②：环境搭建、模型转换、Demo及Tools</a><br>下一篇：<a href="https://wangyujie.space/TDA4VM4/">TDA4④：部署自定义深度学习模型</a></p>
<h1 id="YOLOX部署TDA4VM-SK流程"><a href="#YOLOX部署TDA4VM-SK流程" class="headerlink" title="YOLOX部署TDA4VM-SK流程"></a>YOLOX部署TDA4VM-SK流程</h1><p>TI官方在<a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-modelzoo"> ModelZOO </a>中提供了一系列预训练模型可以直接拿来转换，也提供了<a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-yolov5"> edgeai-YOLOv5 </a>与<a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-yolox"> edgeai-YOLOX </a>等优化的开源项目，可以直接下载提供的YOLOX_s的<a target="_blank" rel="noopener" href="http://software-dl.ti.com/jacinto7/esd/modelzoo/latest/models/vision/detection/coco/edgeai-yolox/yolox-s-ti-lite_39p1_57p9.onnx"> onnx文件 </a>和<a target="_blank" rel="noopener" href="http://software-dl.ti.com/jacinto7/esd/modelzoo/latest/models/vision/detection/coco/edgeai-yolox/yolox_s_ti_lite_metaarch.prototxt"> prototxt文件 </a>，也可以在官方项目上训练自己的模型后再导入。</p>
<p>这里尝试跑通全流程，在 edgeai-YOLOX 项目中训练，得到 <code>.pth</code> 权重文件，使用 export_onnx.py 文件转换为 <code>.onnx</code> 模型文件和 <code>.prototxt</code> 架构配置文件，并导入TIDL，得到部署用的 <code>.bin</code> 文件。<br>主要参考<a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-yolox/blob/main/README_2d_od.md"> edgeai-YOLOX文档 </a>以及<a target="_blank" rel="noopener" href="https://blog.csdn.net/AIRKernel/article/details/126222505"> YOLOX模型训练结果导入及平台移植应用 </a></p>
<img alt="picture 1" data-src="https://github.com/TexasInstruments/edgeai-yolox/raw/main/yolox/utils/figures/Focus.png"/>  

<h2 id="1-使用edgeai-yolox训练模型"><a href="#1-使用edgeai-yolox训练模型" class="headerlink" title="1. 使用edgeai-yolox训练模型"></a>1. 使用edgeai-yolox训练模型</h2><p>目标检测文档：<a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-yolox/blob/main/README_2d_od.md">edgeai-yolox-2d_od</a><br>修改后源码见：<a target="_blank" rel="noopener" href="https://github.com/Arrowes/DMS-YOLOv8/tree/main/TI/edgeai-yolox">Arrowes&#x2F;DMS-YOLOv8&#x2F;tree&#x2F;main&#x2F;TI&#x2F;edgeai-yolox</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/TexasInstruments/edgeai-yolox.git</span><br><span class="line"></span><br><span class="line">conda create -n pytorch python=3.6</span><br><span class="line">./setup.sh  <span class="comment">#若pytorch环境已建好，就不用全部跑通，后面运行时一个个装</span></span><br><span class="line"><span class="comment">#运行demo，pth在文档中下载</span></span><br><span class="line">python tools/demo.py image -f exps/default/yolox_s_ti_lite.py -c yolox-s-ti.pth --path assets/dog.jpg --conf 0.25 --nms 0.45 --tsize 640 --save_result --device gpu --dataset coco</span><br><span class="line"><span class="comment">#报错，注释掉135行self.cad_models = model.head.cad_models，成功</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自建数据集，COCO格式，放在datasets文件夹</span></span><br><span class="line">    COCO </span><br><span class="line">    ├── train2017   <span class="comment">#训练jpg图片</span></span><br><span class="line">    ├── val2017     <span class="comment">#验证jpg图片</span></span><br><span class="line">    └── annotations <span class="comment">#标签json文件</span></span><br><span class="line">        ├── instances_train2017.json</span><br><span class="line">        └── instances_val2017.json</span><br><span class="line"></span><br><span class="line">yolox/data/datasets/coco_classes.py <span class="comment">#修改类别名称</span></span><br><span class="line">yolox/data/datasets/coco.py  <span class="comment">#改size</span></span><br><span class="line">yolox/exp/yolox_base.py   <span class="comment">#类别数量等训练参数,如interval改为1，配置数据增强等</span></span><br><span class="line">exps/default/yolox_s_ti_lite.py <span class="comment">#模型配置文件，在里面修改参数，如模型大小</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#运行训练：</span></span><br><span class="line">python -m yolox.tools.train -n yolox-s-ti-lite -d 0 -b 16 --fp16 -o --cache</span><br><span class="line"><span class="comment">#Save weights to ./YOLOX_outputs/yolox_s_ti_lite</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#导出：</span></span><br><span class="line">python3 tools/export_onnx.py --output-name yolox_s_ti_lite0.onnx -f exps/default/yolox_s_ti_lite.py -c YOLOX_outputs/yolox_s_ti_lite/best_ckpt.pth --export-det</span><br><span class="line"><span class="comment">#生成onnx与prototxt</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#onnx推理：</span></span><br><span class="line">python3 demo/ONNXRuntime/onnx_inference.py -m yolox_s_ti_lite0.onnx -i test.jpg -s 0.3 --input_shape 640,640 --export-det</span><br></pre></td></tr></table></figure>

<h2 id="2-模型文件转ONNX"><a href="#2-模型文件转ONNX" class="headerlink" title="2. 模型文件转ONNX"></a>2. 模型文件转ONNX</h2><p>ONNX(Open Neural Network Exchange)是用于在各种深度学习训练和推理框架转 换的一个中间表示格式。ONNX 定义了一组和环境，平台均无关的标准格式，来增强各种 AI 模型的可交互性，开放性较强。 TIDL 对 ONNX 模型有很好的支持，因此，将训练得到的pth模型文件转换为onnx文件，并利用tidl importer实现模型的编译与量化，具体步骤如下：</p>
<p><del>pycharm进入edgeai-yolox项目，根据提示额外安装requirements</del><br>Window中配置该环境需要安装visual studio build tools，而且很多包报错，因此转ubuntu用vscode搭pytorch环境，非常顺利（vscode插件离线安装：如装python插件，直接进<a target="_blank" rel="noopener" href="https://marketplace.visualstudio.com/vscode"> marketplace </a>下好拖到扩展位置）拓展设置中把Python Default Path改成创建的环境 <code>/home/wyj/anaconda3/envs/pytorch/bin/python</code>，最后用vscode打开项目，F5运行py程序，将.pth转为 <code>.onnx, .prototxt</code> 文件。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pip3 install -U pip &amp;&amp; pip3 install -r requirements.txt</span><br><span class="line">pip3 install -v -e .  <span class="comment"># or  python3 setup.py develop</span></span><br><span class="line"><span class="comment">#安装pycocotools</span></span><br><span class="line">pip3 install cython</span><br><span class="line">pip3 install <span class="string">&#x27;git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI&#x27;</span></span><br><span class="line"><span class="comment">#下载ti的yolox-s-ti-lite.pth放入项目文件夹，运行export，</span></span><br><span class="line">python3 tools/export_onnx.py --output-name yolox_s_ti_lite.onnx -f exps/default/yolox_s_ti_lite.py -c yolox-s-ti-lite.pth</span><br><span class="line"></span><br><span class="line"><span class="comment">#Debug：</span></span><br><span class="line">TypeError: Descriptors cannot not be created directly. &gt; pip install protobuf==3.19.6;</span><br><span class="line">AttributeError: module <span class="string">&#x27;numpy&#x27;</span> has no attribute <span class="string">&#x27;object&#x27;</span>. &gt; pip install numpy==1.23.4</span><br><span class="line"><span class="comment">#成功，生成onnx文件</span></span><br><span class="line"> __main__:main:245 - generated onnx model named yolox_s_ti_lite.onnx</span><br><span class="line"> __main__:main:261 - generated simplified onnx model named yolox_s_ti_lite.onnx</span><br><span class="line"> __main__:main:264 - generated prototxt yolox_s_ti_lite.prototxt</span><br></pre></td></tr></table></figure>
<details>
<summary>yolox_s_ti_lite.prototxt</summary>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">name: <span class="string">&quot;yolox&quot;</span></span><br><span class="line">tidl_yolo &#123;</span><br><span class="line">  yolo_param &#123;</span><br><span class="line">    input: <span class="string">&quot;/head/Concat_output_0&quot;</span></span><br><span class="line">    anchor_width: 8.0</span><br><span class="line">    anchor_height: 8.0&#125;</span><br><span class="line">  yolo_param &#123;</span><br><span class="line">    input: <span class="string">&quot;/head/Concat_3_output_0&quot;</span></span><br><span class="line">    anchor_width: 16.0</span><br><span class="line">    anchor_height: 16.0&#125;</span><br><span class="line">  yolo_param &#123;</span><br><span class="line">    input: <span class="string">&quot;/head/Concat_6_output_0&quot;</span></span><br><span class="line">    anchor_width: 32.0</span><br><span class="line">    anchor_height: 32.0&#125;</span><br><span class="line">detection_output_param &#123;</span><br><span class="line">    num_classes: 80</span><br><span class="line">    share_location: <span class="literal">true</span></span><br><span class="line">    background_label_id: -1</span><br><span class="line">    nms_param &#123;</span><br><span class="line">      nms_threshold: 0.4</span><br><span class="line">      top_k: 500&#125;</span><br><span class="line">    code_type: CODE_TYPE_YOLO_X</span><br><span class="line">    keep_top_k: 200</span><br><span class="line">    confidence_threshold: 0.4&#125;</span><br><span class="line">  name: <span class="string">&quot;yolox&quot;</span></span><br><span class="line">  in_width: 640</span><br><span class="line">  in_height: 640</span><br><span class="line">  output: <span class="string">&quot;detections&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
</details>           

<hr>
<p><a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-yolox/tree/main/demo/ONNXRuntime#yolox-onnxruntime-in-python">ONNXRuntime inference</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> &lt;YOLOX_HOME&gt;</span><br><span class="line">python3 demo/ONNXRuntime/onnx_inference.py -m yolox_s_ti_lite.onnx -i assets/dog.jpg -o output -s 0.3 --input_shape 640,640</span><br><span class="line"><span class="comment">#成功基于ONNXRuntime输出预测结果</span></span><br></pre></td></tr></table></figure>
<img alt="图 1" data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/TDA4VM3onnxinference.jpg" width="50%"/>  

<h2 id="3-模型转换"><a href="#3-模型转换" class="headerlink" title="3. 模型转换"></a>3. 模型转换</h2><p>对于模型转换，硬件不同，使用的工具也不同：</p>
<ol>
<li>EVM：使用TIDL Importer，这是RTOS SDK中提供的工具，有很多例程（SDK8.6中例程文件缺失，copy 8.5的），见a.</li>
<li>SK板：使用TIDL Tools(Edge AI Studio&#x2F;Edge AI Tools)，见<a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-tidl-tools">edgeai-tidl-tools</a>，灵活度高，不支持的算子分配到ARM核，支持的会使用TIDL加速运行，增加了深度学习模型开发和运行的效率。但要求平台有onnx运行环境, 适用于SK板, 见b&#x2F;c.</li>
</ol>
<h3 id="a-使用TIDL-Importer-in-RTOS-SDK"><a href="#a-使用TIDL-Importer-in-RTOS-SDK" class="headerlink" title="a. 使用TIDL Importer (in RTOS SDK)"></a>a. 使用<a target="_blank" rel="noopener" href="https://software-dl.ti.com/jacinto7/esd/processor-sdk-rtos-jacinto7/06_01_01_12/exports/docs/tidl_j7_01_00_01_00/ti_dl/docs/user_guide_html/md_tidl_model_import.html">TIDL Importer</a> (in RTOS SDK)</h3><ol>
<li>模型文件配置：拷贝 .onnx, .prototxt 文件至&#x2F;ti_dl&#x2F;test&#x2F;testvecs&#x2F;models&#x2F;public&#x2F;onnx&#x2F;，<strong>yolox_s_ti_lite.prototxt</strong>中改in_width&amp;height，根据情况改nms_threshold: 0.4，confidence_threshold: 0.4</li>
<li>编写转换配置文件：在&#x2F;testvecs&#x2F;config&#x2F;import&#x2F;public&#x2F;onnx下新建（或复制参考目录下yolov3例程）<strong>tidl_import_yolox_s.txt</strong>，参数配置见<a target="_blank" rel="noopener" href="https://software-dl.ti.com/jacinto7/esd/processor-sdk-rtos-jacinto7/06_01_01_12/exports/docs/tidl_j7_01_00_01_00/ti_dl/docs/user_guide_html/md_tidl_model_import.html">文档</a>, 元架构类型见 <a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-tidl-tools/blob/master/docs/tidl_fsg_od_meta_arch.md">Object detection meta architectures</a>，<code>inData</code>处修改自定义的数据输入</li>
</ol>
<p><em>转换配置文件tidl_import_yolox_s.txt</em></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">modelType       = 2     <span class="comment">#模型类型，0: Caffe, 1: TensorFlow, 2: ONNX, 3: tfLite</span></span><br><span class="line">numParamBits    = 8     <span class="comment">#模型参数的位数，Bit depth for model parameters like Kernel, Bias etc.</span></span><br><span class="line">numFeatureBits  = 8     <span class="comment">#Bit depth for Layer activation</span></span><br><span class="line">quantizationStyle = 3   <span class="comment">#量化方法，Quantization method. 2: Linear Mode. 3: Power of 2 scales（2的幂次）</span></span><br><span class="line">inputNetFile    = <span class="string">&quot;../../test/testvecs/models/public/onnx/yolox-s-ti-lite.onnx&quot;</span> <span class="comment">#Net definition from Training frames work</span></span><br><span class="line">outputNetFile   = <span class="string">&quot;../../test/testvecs/config/tidl_models/onnx/yolo/tidl_net_yolox_s.bin&quot;</span>   <span class="comment">#Output TIDL model with Net and Parameters</span></span><br><span class="line">outputParamsFile = <span class="string">&quot;../../test/testvecs/config/tidl_models/onnx/yolo/tidl_io_yolox_s_&quot;</span>  <span class="comment">#Input and output buffer descriptor file for TIDL ivision interface</span></span><br><span class="line">inDataNorm      = 1     <span class="comment">#1 Enable / 0 Disable Normalization on input tensor.</span></span><br><span class="line">inMean          = 0 0 0 <span class="comment">#Mean value needs to be subtracted for each channel of all input tensors</span></span><br><span class="line">inScale         = 1.0 1.0 1.0   <span class="comment">#Scale value needs to be multiplied after means subtract for each channel of all input tensors，yolov3例程是0.003921568627 0.003921568627 0.003921568627</span></span><br><span class="line">inDataFormat    = 1     <span class="comment">#Input tensor color format. 0: BGR planar, 1: RGB planar</span></span><br><span class="line">inWidth         = 1024  <span class="comment">#each input tensors Width (可以在.prototxt文件中查找到)</span></span><br><span class="line">inHeight        = 512   <span class="comment">#each input tensors Height</span></span><br><span class="line">inNumChannels   = 3     <span class="comment">#each input tensors Number of channels</span></span><br><span class="line">numFrames       = 1     <span class="comment">#Number of input tensors to be processed from the input file</span></span><br><span class="line">inData          =   <span class="string">&quot;../../test/testvecs/config/detection_list.txt&quot;</span> <span class="comment">#Input tensors File for Reading</span></span><br><span class="line">perfSimConfig   = ../../test/testvecs/config/import/device_config.cfg   <span class="comment">#Network Compiler Configuration file</span></span><br><span class="line">inElementType   = 0     <span class="comment">#Format for each input feature, 0 : 8bit Unsigned, 1 : 8bit Signed</span></span><br><span class="line">metaArchType    = 6     <span class="comment">#网络使用的元架构类型，Meta Architecture used by the network，ssd mobilenetv2 = 3, yolov3 = 4, efficientdet tflite = 5, yolov5 yolox = 6</span></span><br><span class="line">metaLayersNamesList =  <span class="string">&quot;../../test/models/pubilc/onnx/yolox_s_ti_lite.prototxt&quot;</span> <span class="comment">#架构配置文件，Configuration files describing the details of Meta Arch</span></span><br><span class="line">postProcType    = 2     <span class="comment">#后处理，Post processing on output tensor. 0 : Disable, 1- Classification top 1 and 5 accuracy, 2 – Draw bounding box for OD, 3 - Pixel level color blending</span></span><br><span class="line">debugTraceLevel = 1     <span class="comment">#输出日志</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li><p>模型导入<br>使用TIDL import tool，得到可执行文件 <code>.bin</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$&#123;TIDL_INSTALL_PATH&#125;</span>/ti_dl/utils/tidlModelImport</span><br><span class="line">./out/tidl_model_import.out <span class="variable">$&#123;TIDL_INSTALL_PATH&#125;</span>/ti_dl/test/testvecs/config/import/public/onnx/tidl_import_yolox.txt</span><br><span class="line"><span class="comment">#successful Memory allocation</span></span><br><span class="line"><span class="comment">#../../test/testvecs/config/tidl_models/onnx/生成的文件分析：</span></span><br><span class="line">tidl_net_yolox_s.bin        <span class="comment">#Compiled network file 网络模型数据</span></span><br><span class="line">tidl_io_yolox_s_1.bin       <span class="comment">#Compiled I/O file 网络输入配置文件</span></span><br><span class="line">tidl_net_yolox_s.bin.svg    <span class="comment">#tidlModelGraphviz tool生成的网络图</span></span><br><span class="line">tidl_out.png, tidl_out.txt  <span class="comment">#执行的目标检测测试结果，与第三步TIDL运行效果一致 txt:[class, source, confidence, Lower left point(x,y), upper right point(x,y) ]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Debug，本来使用官方的yolox_s.pth转成onnx后导入，发现报错：</span></span><br><span class="line">Step != 1 is NOT supported <span class="keyword">for</span> Slice Operator -- /backbone/backbone/stem/Slice_3 </span><br><span class="line"><span class="comment">#因为&quot;the slice operations in Focus layer are not embedded friendly&quot;，因此ti提供yolox-s-ti-lite，优化后的才能直接导入</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>TIDL运行(PC inference)</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在文件ti_dl/test/testvecs/config/config_list.txt顶部加入:</span></span><br><span class="line">1 testvecs/config/infer/public/onnx/tidl_infer_yolox.txt</span><br><span class="line">0</span><br><span class="line"></span><br><span class="line"><span class="comment">#新建tidl_infer_yolox.txt:</span></span><br><span class="line">inFileFormat    = 2</span><br><span class="line">numFrames       = 1</span><br><span class="line">netBinFile      = <span class="string">&quot;testvecs/config/tidl_models/onnx/yolo/tidl_net_yolox_s.bin&quot;</span></span><br><span class="line">ioConfigFile    = <span class="string">&quot;testvecs/config/tidl_models/onnx/yolo/tidl_io_yolox_s_1.bin&quot;</span></span><br><span class="line">inData  =   testvecs/config/detection_list.txt</span><br><span class="line">outData =   testvecs/output/tidl_yolox_od.bin</span><br><span class="line">inResizeMode    = 0</span><br><span class="line">debugTraceLevel = 0</span><br><span class="line">writeTraceLevel = 0</span><br><span class="line">postProcType    = 2</span><br><span class="line"></span><br><span class="line"><span class="comment">#运行，结果在ti_dl/test/testvecs/output/</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$&#123;TIDL_INSTALL_PATH&#125;</span>/ti_dl/test</span><br><span class="line">./PC_dsp_test_dl_algo.out</span><br></pre></td></tr></table></figure>
<img alt="图 2" data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/TDA4VM3sdktidlyolox.png" width="50%"/></li>
</ol>
<h3 id="b-使用Edge-AI-Studio"><a href="#b-使用Edge-AI-Studio" class="headerlink" title="b. 使用Edge AI Studio"></a>b. 使用<a target="_blank" rel="noopener" href="https://dev.ti.com/edgeaistudio/">Edge AI Studio</a></h3><p>参考他人实例：<a target="_blank" rel="noopener" href="https://www.hackster.io/whitney-knitter/practicing-yoga-with-ai-human-pose-estimation-on-the-tda4vm-fe2549">YOLOX-Yoga</a><br>使用<code>Edge AI Studio &gt; Model Analyzer &gt; Custom models &gt; ONNX runtime &gt; custom-model-onnx.ipynb</code>例程, 并结合 <code>OD.ipynb</code> 例程进行修改</p>
<p><em>YOLOX.ipynb</em></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> onnxruntime <span class="keyword">as</span> rt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment">#/notebooks/scripts/utils.py:</span></span><br><span class="line"><span class="keyword">from</span> scripts.utils <span class="keyword">import</span> imagenet_class_to_name, download_model, loggerWritter, get_svg_path, get_preproc_props, single_img_visualise, det_box_overlay</span><br></pre></td></tr></table></figure>
<p>其中scripts.utils中的代码细节在<code>/notebooks/scripts/utils.py</code></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#预处理</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">image_path</span>):</span><br><span class="line">    img = cv2.imread(image_path) <span class="comment"># 使用OpenCV读取图像</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;原始图像：&#x27;</span>, img.shape, img.dtype)</span><br><span class="line">    img = cv2.resize(img, (<span class="number">640</span>, <span class="number">640</span>), interpolation=cv2.INTER_CUBIC)</span><br><span class="line">    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line">    img = img.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.0</span></span><br><span class="line">    img = (img * <span class="number">255</span>).astype(<span class="string">&#x27;uint8&#x27;</span>)</span><br><span class="line">    img = np.expand_dims(img, axis=<span class="number">0</span>) <span class="comment"># 扩展图片数组维度</span></span><br><span class="line">    img = np.transpose(img, (<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)) <span class="comment"># NHWC 格式（batch_size，height, width，channels）转换为 NCHW 格式</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;处理后的图像：&#x27;</span>, img.shape, img.dtype)</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure>
<p>图片的预处理十分重要，调试时注意print图片数据，避免处理出错</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#配置</span></span><br><span class="line">images = [</span><br><span class="line"><span class="string">&#x27;WYJ/dog.jpg&#x27;</span>,</span><br><span class="line">]</span><br><span class="line">output_dir = <span class="string">&#x27;WYJ/output&#x27;</span><span class="comment">#优化后的ONNX模型将保存的输出目录</span></span><br><span class="line">onnx_model_path = <span class="string">&#x27;WYJ/yolox_s_lite_640x640_20220221_model.onnx&#x27;</span></span><br><span class="line">prototxt_path = <span class="string">&#x27;WYJ/yolox_s_lite_640x640_20220221_model.prototxt&#x27;</span></span><br><span class="line"><span class="keyword">with</span> loggerWritter(<span class="string">&quot;WYJ/logs&quot;</span>):<span class="comment"># stdout and stderr saved to a *.log file.</span></span><br><span class="line">    compile_options = &#123;</span><br><span class="line">      <span class="string">&#x27;tidl_tools_path&#x27;</span> : os.environ[<span class="string">&#x27;TIDL_TOOLS_PATH&#x27;</span>],</span><br><span class="line">      <span class="string">&#x27;artifacts_folder&#x27;</span> : output_dir,</span><br><span class="line">      <span class="string">&#x27;tensor_bits&#x27;</span> : <span class="number">8</span>,</span><br><span class="line">      <span class="string">&#x27;accuracy_level&#x27;</span> : <span class="number">1</span>,</span><br><span class="line">      <span class="string">&#x27;advanced_options:calibration_frames&#x27;</span> : <span class="built_in">len</span>(images), </span><br><span class="line">      <span class="string">&#x27;advanced_options:calibration_iterations&#x27;</span> : <span class="number">3</span>, <span class="comment"># used if accuracy_level = 1</span></span><br><span class="line">      <span class="string">&#x27;debug_level&#x27;</span> : <span class="number">1</span>, <span class="comment"># 设置调试级别，级别越高提供的调试信息越详细</span></span><br><span class="line">      <span class="comment">#&#x27;advanced_options:output_feature_16bit_names_list&#x27;: &#x27;370, 680, 990, 1300&#x27;,    </span></span><br><span class="line">      <span class="comment">#&#x27;deny_list&#x27;: &#x27;ScatterND&#x27;, #&#x27; Conv, Relu, Add, Concat, Resize&#x27;, # MaxPool</span></span><br><span class="line">      <span class="string">&#x27;object_detection:meta_arch_type&#x27;</span>: <span class="number">6</span>,</span><br><span class="line">      <span class="string">&#x27;object_detection:meta_layers_names_list&#x27;</span>: prototxt_path,    </span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment"># create the output dir if not present &amp; clear the directory</span></span><br><span class="line">os.makedirs(output_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(output_dir, topdown=<span class="literal">False</span>):</span><br><span class="line">    [os.remove(os.path.join(root, f)) <span class="keyword">for</span> f <span class="keyword">in</span> files]</span><br><span class="line">    [os.rmdir(os.path.join(root, d)) <span class="keyword">for</span> d <span class="keyword">in</span> dirs]</span><br></pre></td></tr></table></figure>
<p>object_detection:meta_arch_type、meta_layers_names_list两个参数在OD任务中必须配置，否则内核直接奔溃，参数配置文档中也有说明：<a target="_blank" rel="noopener" href="https://github.com/TexasInstruments/edgeai-tidl-tools/blob/master/examples/osrt_python/README.md#object-detection-model-specific-options">object-detection-model-specific-options</a></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#模型转换</span></span><br><span class="line">so = rt.SessionOptions()</span><br><span class="line">EP_list = [<span class="string">&#x27;TIDLCompilationProvider&#x27;</span>,<span class="string">&#x27;CPUExecutionProvider&#x27;</span>]</span><br><span class="line">sess = rt.InferenceSession(onnx_model_path ,providers=EP_list, provider_options=[compile_options, &#123;&#125;], sess_options=so)</span><br><span class="line"><span class="comment"># 获取所有输入输出详细信息</span></span><br><span class="line">input_details = sess.get_inputs()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model input details:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> input_details:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line">output_details = sess.get_outputs()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model output details:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> output_details:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line"><span class="comment">#运行</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm.trange(<span class="built_in">len</span>(images)):</span><br><span class="line">    processed_image = preprocess(images[i])</span><br><span class="line">    output=<span class="literal">None</span></span><br><span class="line">    output = <span class="built_in">list</span>(sess.run(<span class="literal">None</span>, &#123;input_details[<span class="number">0</span>].name :processed_image &#125;))</span><br></pre></td></tr></table></figure>
<p>打印输入输出信息，运行编译</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#画框</span></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageDraw</span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&quot;WYJ/dog.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line">width_scale = <span class="number">640</span> / img.size[<span class="number">0</span>]</span><br><span class="line">height_scale = <span class="number">640</span> / img.size[<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 创建ImageDraw对象</span></span><br><span class="line">draw = ImageDraw.Draw(img)</span><br><span class="line"><span class="comment"># 遍历所有边界框，画出矩形</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">int</span>(output[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">0</span>])):</span><br><span class="line">    <span class="comment"># 取出顶点坐标和置信度</span></span><br><span class="line">    xmin, ymin, xmax, ymax, conf = <span class="built_in">tuple</span>(output[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>][i].tolist())</span><br><span class="line">    <span class="keyword">if</span>(conf &gt; <span class="number">0.4</span>) :</span><br><span class="line">        cls = <span class="built_in">int</span>(output[<span class="number">1</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>][i])  <span class="comment"># 取出类别编号</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;class:&#x27;</span>, cls, <span class="string">&#x27;, box:&#x27;</span>,output[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>][i])</span><br><span class="line">        color = (<span class="number">255</span>, cls*<span class="number">10</span>, cls*<span class="number">100</span>)        <span class="comment"># 选择不同颜色表示不同类别</span></span><br><span class="line">        <span class="comment"># 画出矩形框</span></span><br><span class="line">        draw.rectangle(((xmin/ width_scale, ymin/ height_scale), (xmax/ width_scale, ymax/ height_scale)), outline=color, width=<span class="number">2</span>)</span><br><span class="line">img.show()  <span class="comment"># 显示画好的图像</span></span><br></pre></td></tr></table></figure>
<p>画框，引入了缩放比例，否则框的位置不对<br><img alt="图 3" data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/TDA4VM3studioyolox.png" width="50%"/>  </p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Subgraphs visualization</span></span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Markdown <span class="keyword">as</span> md</span><br><span class="line"></span><br><span class="line">subgraph_link =get_svg_path(output_dir) </span><br><span class="line"><span class="keyword">for</span> sg <span class="keyword">in</span> subgraph_link:</span><br><span class="line">    hl_text = os.path.join(*Path(sg).parts[<span class="number">4</span>:])</span><br><span class="line">    sg_rel = os.path.join(<span class="string">&#x27;../&#x27;</span>, sg)</span><br><span class="line">    display(md(<span class="string">&quot;[&#123;&#125;](&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(hl_text,sg_rel)))</span><br></pre></td></tr></table></figure>
<p>生成两个.svg网络可视化图的链接</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#模型推理</span></span><br><span class="line">EP_list = [<span class="string">&#x27;TIDLExecutionProvider&#x27;</span>,<span class="string">&#x27;CPUExecutionProvider&#x27;</span>]</span><br><span class="line">sess = rt.InferenceSession(onnx_model_path ,providers=EP_list, provider_options=[compile_options, &#123;&#125;], sess_options=so)</span><br><span class="line"></span><br><span class="line">input_details = sess.get_inputs()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):<span class="comment">#Running inference several times to get an stable performance output</span></span><br><span class="line">    output = <span class="built_in">list</span>(sess.run(<span class="literal">None</span>, &#123;input_details[<span class="number">0</span>].name : preprocess(<span class="string">&#x27;WYJ/dog.jpg&#x27;</span>)&#125;))</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scripts.utils <span class="keyword">import</span> plot_TI_performance_data, plot_TI_DDRBW_data, get_benchmark_output</span><br><span class="line">stats = sess.get_TI_benchmark_data()</span><br><span class="line">fig, ax = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">1</span>, figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">plot_TI_performance_data(stats, axis=ax)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">tt, st, rb, wb = get_benchmark_output(stats)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Statistics : \n Inferences Per Second   : <span class="subst">&#123;<span class="number">1000.0</span>/tt :<span class="number">7.2</span>f&#125;</span> fps&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27; Inference Time Per Image : <span class="subst">&#123;tt :<span class="number">7.2</span>f&#125;</span> ms  \n DDR BW Per Image        : <span class="subst">&#123;rb+ wb : <span class="number">7.2</span>f&#125;</span> MB&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>推理，注意<code>TIDLCompilationProvider</code>和<code>TIDLExecutionProvider</code>的区别<br><img alt="图 2" data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/TDA4VM3yoloxs.png" width="90%"/>  </p>
<blockquote>
<p>Statistics :<br>  Inferences Per Second   :  104.44 fps<br>  Inference Time Per Image :    9.57 ms<br>  DDR BW Per Image        :   16.22 MB</p>
</blockquote>
<p><strong>Debug</strong>:</p>
<ul>
<li>将custom-model-onnx 替换为自己的模型后报错，且内核经常挂掉，这不是服务器的问题，而是代码中有错误引发 Jupyter 中的某种内存分配问题并kill内核.（如，索引路径错误，模型不存在，config参数配置错误）—— <a target="_blank" rel="noopener" href="https://e2e.ti.com/support/processors-group/processors/f/processors-forum/1214094/tda4vm-inference-with-custom-artifacts-kills-kernel-in-edge-ai-studio/4658432?tisearch=e2e-sitesearch&keymatch=edge%252520ai%252520studio#4658432">E2E:Kills Kernel in Edge AI Studio</a></li>
<li>在My Workspace中， 右上角<code>New &gt; Terminal</code> 可以打开终端，便于进一步的调试</li>
<li>prebuilt-models中的预训练模型每次重启EVM都要先重新解压:<br><code>cd notebooks/prebuilt-models/8bits/</code><br><code>find . -name &quot;*.tar.gz&quot; -exec tar --one-top-level -zxvf &quot;&#123;&#125;&quot; \;</code></li>
<li>内核频繁挂掉：重启EVM</li>
</ul>
<h3 id="c-使用EdgeAI-TIDL-Tools"><a href="#c-使用EdgeAI-TIDL-Tools" class="headerlink" title="c. 使用EdgeAI-TIDL-Tools"></a>c. 使用EdgeAI-TIDL-Tools</h3><p>此处仅简单介绍YOLOX的最简部署流程，详见：<a href="https://wangyujie.space/TDA4VM4/#EdgeAI-TIDL-Tools">TDA4VM4_EdgeAI-TIDL-Tools</a></p>
<p>TI部署相关修改代码：<a target="_blank" rel="noopener" href="https://github.com/Arrowes/DMS-YOLOv8/tree/main/TI">DMS-YOLOv8: TI</a><br>EdgeAI-TIDL-Tools版本：08_06_00_05</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#运行训练：</span></span><br><span class="line">python -m yolox.tools.train -n yolox-s-ti-lite -d 0 -b 64 --fp16 -o --cache</span><br><span class="line"><span class="comment">#导出：</span></span><br><span class="line">python3 tools/export_onnx.py --output-name yolox_s_ti_lite0.onnx -f exps/default/yolox_s_ti_lite.py -c YOLOX_outputs/yolox_s_ti_lite/best_ckpt.pth --export-det</span><br><span class="line"><span class="comment">#onnx推理：</span></span><br><span class="line">python3 demo/ONNXRuntime/onnx_inference.py -m yolox_s_ti_lite0.onnx -i test.jpg -s 0.3 --input_shape 640,640 --export-det</span><br><span class="line"></span><br><span class="line"><span class="comment">#onnx拷贝到tool/models,/examples/osrt_python改model_configs的模型路径和类别数量</span></span><br><span class="line"><span class="comment">#tools根目录运行</span></span><br><span class="line">./scripts/yolo_compile.sh</span><br><span class="line"><span class="comment">#模型结果在model-artifacts/模型名称</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#挂载SD卡，model_zoo新建模型文件夹，拷贝模型</span></span><br><span class="line">YOLOX/</span><br><span class="line">├── artifacts</span><br><span class="line">│   ├── allowedNode.txt</span><br><span class="line">│   ├── detections_tidl_io_1.bin</span><br><span class="line">│   ├── detections_tidl_net.bin</span><br><span class="line">│   └── onnxrtMetaData.txt</span><br><span class="line">├── dataset.yaml    <span class="comment">#改</span></span><br><span class="line">├── model</span><br><span class="line">│   └── yolox_s_ti_lite0.onnx</span><br><span class="line">├── param.yaml  <span class="comment">#拷贝然后改</span></span><br><span class="line">└── run.log</span><br><span class="line"></span><br><span class="line"><span class="comment">#dataset.yaml</span></span><br><span class="line">categories:</span><br><span class="line">- supercategory: distract</span><br><span class="line">  <span class="built_in">id</span>: 1</span><br><span class="line">  name: cup</span><br><span class="line">- supercategory: distract</span><br><span class="line">  <span class="built_in">id</span>: 2</span><br><span class="line">  name: hand</span><br><span class="line">- supercategory: distract</span><br><span class="line">  <span class="built_in">id</span>: 3</span><br><span class="line">  name: phone</span><br><span class="line">- supercategory: distract</span><br><span class="line">  <span class="built_in">id</span>: 4</span><br><span class="line">  name: wheel</span><br><span class="line"></span><br><span class="line"><span class="comment">#param.yaml（copy from model_zoo_8220）</span></span><br><span class="line">threshold: 0.2  <span class="comment">#好像没用</span></span><br><span class="line">model_path: model/yolox_s_ti_lite0.onnx</span><br><span class="line"></span><br><span class="line"><span class="comment">#rootfs/opt/edgeai-gst-apps/configs改yolo.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#SD卡上板</span></span><br><span class="line">sudo minicom -D /dev/ttyUSB2 -c on</span><br><span class="line"><span class="comment">#root登录，ctrl+A Z W换行，运行</span></span><br><span class="line"><span class="built_in">cd</span> /opt/edgeai-gst-apps/apps_cpp &amp;&amp; ./bin/Release/app_edgeai ../configs/yolo.yaml</span><br></pre></td></tr></table></figure>

<h2 id="4-板端运行-TDA4VM-SK"><a href="#4-板端运行-TDA4VM-SK" class="headerlink" title="4. 板端运行(TDA4VM-SK)"></a>4. 板端运行(TDA4VM-SK)</h2><p>SK板环境搭建见：<a href="https://wangyujie.space/TDA4VM2/#TDA4VM-SK-%E9%85%8D%E7%BD%AE">TDA4VM2_TDA4VM-SK-配置</a><br>注意SK的镜像版本需要与EdgeAI-TIDL-Tools版本一致，此处均为08_06_00_05</p>
<p><del>连接SK板进入minicom串口通讯传输模型文件(失败)</del>（若能连网线通过jupyternotebook配置更方便，这里网络有限制所以配置都通过SD卡进行）</p>
<p>通过SD卡配置编译生成的模型，配置模型文件夹yolox放入modelzoo文件夹：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model_zoo/yolox/</span><br><span class="line">├── artifacts <span class="comment">#存放编译生成的工件</span></span><br><span class="line">│   ├── allowedNode.txt</span><br><span class="line">│   ├── detslabels_tidl_io_1.bin</span><br><span class="line">│   ├── detslabels_tidl_net.bin</span><br><span class="line">│   └── onnxrtMetaData.txt</span><br><span class="line">├── dataset.yaml  <span class="comment">#数据集类别</span></span><br><span class="line">├── model</span><br><span class="line">│   ├── yolox_s_lite_640x640_20220221_model.onnx  <span class="comment">#onnx模型</span></span><br><span class="line">│   └── yolox_s_lite_640x640_20220221_model.prototxt  <span class="comment">#可省略</span></span><br><span class="line">└── param.yaml  <span class="comment">#配置文件, 需要修改model_path,threshold等，可复制别的模型yaml（如8220）, 否则可能少很多参数</span></span><br></pre></td></tr></table></figure>
<p>通过SD卡配置object_detection.yaml，在model参数中索引上面建立的模型文件夹</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过minicom连接串口</span></span><br><span class="line">sudo minicom -D /dev/ttyUSB2 -c on</span><br><span class="line">root <span class="comment">#登录</span></span><br><span class="line"><span class="comment">#运行yolox_s实例</span></span><br><span class="line"><span class="built_in">cd</span> /opt/edgeai-gst-apps/apps_cpp</span><br><span class="line">./bin/Release/app_edgeai ../configs/object_detection.yaml</span><br></pre></td></tr></table></figure>

<h3 id="修改app-edgeai（optional）"><a href="#修改app-edgeai（optional）" class="headerlink" title="修改app_edgeai（optional）"></a>修改app_edgeai（optional）</h3><p>在<code>opt\edgeai-gst-apps\apps_cpp\</code>完成修改后重新make:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Regular builds (Build_Instructions.txt)</span></span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">make</span><br></pre></td></tr></table></figure>

<h2 id="5-性能评估"><a href="#5-性能评估" class="headerlink" title="5. 性能评估"></a>5. 性能评估</h2><p>Docs: <a target="_blank" rel="noopener" href="https://software-dl.ti.com/jacinto7/esd/processor-sdk-linux-sk-tda4vm/latest/exports/docs/performance_visualizer.html#">Performance Visualization Tool</a><br>运行实例时，会在运行文件的上一级<code>../perf_Logs/</code>中生成 <code>.md</code> 格式的<strong>Performance Logs</strong>，最多15个，运行时会不断覆写</p>
<p>也可以使用Perfstats tool, 把运行状态在terminal print:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#构建工具</span></span><br><span class="line"><span class="built_in">cd</span> /opt/edgeai-gst-apps/scripts/perf_stats</span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">cmake .. &amp;&amp; make</span><br><span class="line"><span class="comment">#运行评估</span></span><br><span class="line"><span class="built_in">cd</span> /opt/edgeai-gst-apps/scripts/perf_stats/build</span><br><span class="line">../bin/Release/perf_stats -l</span><br></pre></td></tr></table></figure>
<p>此外，使用官方提供的可视化工具Visualization tool是最佳选择，但是要装Docker<br><img data-src="https://software-dl.ti.com/jacinto7/esd/processor-sdk-linux-sk-tda4vm/latest/exports/docs/_images/perf_plots.png"></p>
<h1 id="Performance-Logs"><a href="#Performance-Logs" class="headerlink" title="Performance Logs"></a>Performance Logs</h1><h2 id="Summary-of-CPU-load"><a href="#Summary-of-CPU-load" class="headerlink" title="Summary of CPU load"></a>Summary of CPU load</h2><table>
<thead>
<tr>
<th>CPU</th>
<th>TOTAL LOAD %</th>
</tr>
</thead>
<tbody><tr>
<td>mpu1_0</td>
<td>40.83</td>
</tr>
<tr>
<td>mcu2_0</td>
<td>7. 0</td>
</tr>
<tr>
<td>mcu2_1</td>
<td>1. 0</td>
</tr>
<tr>
<td>c6x_1</td>
<td>0. 0</td>
</tr>
<tr>
<td>c6x_2</td>
<td>1. 0</td>
</tr>
<tr>
<td>c7x_1</td>
<td>32. 0</td>
</tr>
</tbody></table>
<h2 id="HWA-performance-statistics"><a href="#HWA-performance-statistics" class="headerlink" title="HWA performance statistics"></a>HWA performance statistics</h2><table>
<thead>
<tr>
<th>HWA（Hardware Accelerator）</th>
<th>LOAD（Million Operations per second）</th>
</tr>
</thead>
<tbody><tr>
<td>MSC0（Multiply and Accumulate）</td>
<td>6.94 % ( 42 MP&#x2F;s )</td>
</tr>
<tr>
<td>MSC1</td>
<td>6.74 % ( 55 MP&#x2F;s )</td>
</tr>
</tbody></table>
<h2 id="DDR-performance-statistics"><a href="#DDR-performance-statistics" class="headerlink" title="DDR performance statistics"></a>DDR performance statistics</h2><table>
<thead>
<tr>
<th>DDR BW</th>
<th>AVG</th>
<th>PEAK</th>
</tr>
</thead>
<tbody><tr>
<td>READ BW</td>
<td>1509 MB&#x2F;s</td>
<td>5713 MB&#x2F;s</td>
</tr>
<tr>
<td>WRITE BW</td>
<td>721 MB&#x2F;s</td>
<td>3643 MB&#x2F;s</td>
</tr>
<tr>
<td>TOTAL BW</td>
<td>2230 MB&#x2F;s</td>
<td>9356 MB&#x2F;s</td>
</tr>
</tbody></table>
<h2 id="Detailed-CPU-performance-memory-statistics"><a href="#Detailed-CPU-performance-memory-statistics" class="headerlink" title="Detailed CPU performance&#x2F;memory statistics"></a>Detailed CPU performance&#x2F;memory statistics</h2><h3 id="CPU-mcu2-0"><a href="#CPU-mcu2-0" class="headerlink" title="CPU: mcu2_0"></a>CPU: mcu2_0</h3><table>
<thead>
<tr>
<th>TASK</th>
<th>TASK LOAD</th>
</tr>
</thead>
<tbody><tr>
<td>IPC_RX</td>
<td>0.34 %</td>
</tr>
<tr>
<td>REMOTE_SRV</td>
<td>0.30 %</td>
</tr>
<tr>
<td>LOAD_TEST</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_CPU_0</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_V1NF</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_V1LDC1</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_V1SC1</td>
<td>3. 9 %</td>
</tr>
<tr>
<td>TIVX_V1MSC2</td>
<td>3.24 %</td>
</tr>
<tr>
<td>TIVXVVISS1</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_CAPT1</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_CAPT2</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_DISP1</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_DISP2</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_CSITX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_CAPT3</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_CAPT4</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_CAPT5</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_CAPT6</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_CAPT7</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_CAPT8</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_DPM2M1</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_DPM2M2</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_DPM2M3</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_DPM2M4</td>
<td>0. 0 %</td>
</tr>
</tbody></table>
<h4 id="CPU-Heap-Table"><a href="#CPU-Heap-Table" class="headerlink" title="CPU Heap Table"></a>CPU Heap Table</h4><table>
<thead>
<tr>
<th>HEAP</th>
<th>Size</th>
<th>Free</th>
<th>Unused</th>
</tr>
</thead>
<tbody><tr>
<td>DDR_LOCAL_MEM</td>
<td>16777216 B</td>
<td>16768256 B</td>
<td>99 %</td>
</tr>
<tr>
<td>L3_MEM</td>
<td>262144 B</td>
<td>261888 B</td>
<td>99 %</td>
</tr>
</tbody></table>
<details>
<summary>CPU: mcu2_1</summary>

<h3 id="CPU-mcu2-1"><a href="#CPU-mcu2-1" class="headerlink" title="CPU: mcu2_1"></a>CPU: mcu2_1</h3><table>
<thead>
<tr>
<th>TASK</th>
<th>TASK LOAD</th>
</tr>
</thead>
<tbody><tr>
<td>IPC_RX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>REMOTE_SRV</td>
<td>0.18 %</td>
</tr>
<tr>
<td>LOAD_TEST</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_CPU_1</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_SDE</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_DOF</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_RX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
</tbody></table>
<h4 id="CPU-Heap-Table-1"><a href="#CPU-Heap-Table-1" class="headerlink" title="CPU Heap Table"></a>CPU Heap Table</h4><table>
<thead>
<tr>
<th>HEAP</th>
<th>Size</th>
<th>Free</th>
<th>Unused</th>
</tr>
</thead>
<tbody><tr>
<td>DDR_LOCAL_MEM</td>
<td>16777216 B</td>
<td>16773376 B</td>
<td>99 %</td>
</tr>
<tr>
<td>L3_MEM</td>
<td>262144 B</td>
<td>262144 B</td>
<td>100 %</td>
</tr>
</tbody></table>
</details>

<details>
<summary>CPU: c6x_1</summary>

<h3 id="CPU-c6x-1"><a href="#CPU-c6x-1" class="headerlink" title="CPU: c6x_1"></a>CPU: c6x_1</h3><table>
<thead>
<tr>
<th>TASK</th>
<th>TASK LOAD</th>
</tr>
</thead>
<tbody><tr>
<td>IPC_RX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>REMOTE_SRV</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>LOAD_TEST</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_CPU</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_RX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
</tbody></table>
<h4 id="CPU-Heap-Table-2"><a href="#CPU-Heap-Table-2" class="headerlink" title="CPU Heap Table"></a>CPU Heap Table</h4><table>
<thead>
<tr>
<th>HEAP</th>
<th>Size</th>
<th>Free</th>
<th>Unused</th>
</tr>
</thead>
<tbody><tr>
<td>DDR_LOCAL_MEM</td>
<td>16777216 B</td>
<td>16773376 B</td>
<td>99 %</td>
</tr>
<tr>
<td>L2_MEM</td>
<td>229376 B</td>
<td>229376 B</td>
<td>100 %</td>
</tr>
<tr>
<td>DDR_SCRATCH_MEM</td>
<td>50331648 B</td>
<td>50331648 B</td>
<td>100 %</td>
</tr>
</tbody></table>
</details>

<details>
<summary>CPU: c6x_2</summary>

<h3 id="CPU-c6x-2"><a href="#CPU-c6x-2" class="headerlink" title="CPU: c6x_2"></a>CPU: c6x_2</h3><table>
<thead>
<tr>
<th>TASK</th>
<th>TASK LOAD</th>
</tr>
</thead>
<tbody><tr>
<td>IPC_RX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>REMOTE_SRV</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>LOAD_TEST</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_CPU</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_RX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
</tbody></table>
<h4 id="CPU-Heap-Table-3"><a href="#CPU-Heap-Table-3" class="headerlink" title="CPU Heap Table"></a>CPU Heap Table</h4><table>
<thead>
<tr>
<th>HEAP</th>
<th>Size</th>
<th>Free</th>
<th>Unused</th>
</tr>
</thead>
<tbody><tr>
<td>DDR_LOCAL_MEM</td>
<td>16777216 B</td>
<td>16773376 B</td>
<td>99 %</td>
</tr>
<tr>
<td>L2_MEM</td>
<td>229376 B</td>
<td>229376 B</td>
<td>100 %</td>
</tr>
<tr>
<td>DDR_SCRATCH_MEM</td>
<td>50331648 B</td>
<td>50331648 B</td>
<td>100 %</td>
</tr>
</tbody></table>
</details>

<h3 id="CPU-c7x-1"><a href="#CPU-c7x-1" class="headerlink" title="CPU: c7x_1"></a>CPU: c7x_1</h3><table>
<thead>
<tr>
<th>TASK</th>
<th>TASK LOAD</th>
</tr>
</thead>
<tbody><tr>
<td>IPC_RX</td>
<td>0. 5 %</td>
</tr>
<tr>
<td>REMOTE_SRV</td>
<td>0. 1 %</td>
</tr>
<tr>
<td>LOAD_TEST</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_C71_P1</td>
<td>31.38 %</td>
</tr>
<tr>
<td>TIVX_C71_P2</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_C71_P3</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_C71_P4</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_C71_P5</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_C71_P6</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_C71_P7</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>TIVX_C71_P8</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_RX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
<tr>
<td>IPC_TEST_TX</td>
<td>0. 0 %</td>
</tr>
</tbody></table>
<h4 id="CPU-Heap-Table-4"><a href="#CPU-Heap-Table-4" class="headerlink" title="CPU Heap Table"></a>CPU Heap Table</h4><table>
<thead>
<tr>
<th>HEAP</th>
<th>Size</th>
<th>Free</th>
<th>Unused</th>
</tr>
</thead>
<tbody><tr>
<td>DDR_LOCAL_MEM</td>
<td>268435456 B</td>
<td>232984320 B</td>
<td>86 %</td>
</tr>
<tr>
<td>L3_MEM</td>
<td>8159232 B</td>
<td>0 B</td>
<td>0 %</td>
</tr>
<tr>
<td>L2_MEM</td>
<td>458752 B</td>
<td>458752 B</td>
<td>100 %</td>
</tr>
<tr>
<td>L1_MEM</td>
<td>16384 B</td>
<td>0 B</td>
<td>0 %</td>
</tr>
<tr>
<td>DDR_SCRATCH_MEM</td>
<td>385875968 B</td>
<td>367400145 B</td>
<td>95 %</td>
</tr>
</tbody></table>
<h2 id="Performance-point-statistics"><a href="#Performance-point-statistics" class="headerlink" title="Performance point statistics"></a>Performance point statistics</h2><h3 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h3><table>
<thead>
<tr>
<th>PERF</th>
<th>avg (usecs)</th>
<th>min&#x2F;max (usecs)</th>
<th>number of executions</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>33352</td>
<td>0 &#x2F; 412578</td>
<td>9556</td>
</tr>
</tbody></table>
<h3 id="FPS"><a href="#FPS" class="headerlink" title="FPS"></a>FPS</h3><table>
<thead>
<tr>
<th>PERF</th>
<th>Frames per sec (FPS)</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>29.98</td>
</tr>
</tbody></table>
<h2 id="Temperature-statistics"><a href="#Temperature-statistics" class="headerlink" title="Temperature statistics"></a>Temperature statistics</h2><table>
<thead>
<tr>
<th>ZONE</th>
<th>TEMPERATURE</th>
</tr>
</thead>
<tbody><tr>
<td>CPU</td>
<td>50.93 Celsius</td>
</tr>
<tr>
<td>WKUP</td>
<td>49.52 Celsius</td>
</tr>
<tr>
<td>C7X</td>
<td>51.86 Celsius</td>
</tr>
<tr>
<td>GPU</td>
<td>51.63 Celsius</td>
</tr>
<tr>
<td>R5F</td>
<td>50.93 Celsius</td>
</tr>
</tbody></table>
<hr>
<blockquote>
<p>TDA4系列文章：<br><a href="https://wangyujie.space/TDA4VM/">TDA4①：SDK, TIDL, OpenVX</a><br><a href="https://wangyujie.space/TDA4VM2/">TDA4②：环境搭建、模型转换、Demo及Tools</a><br><a href="https://wangyujie.space/TDA4VM3/">TDA4③：YOLOX的模型转换与SK板端运行</a><br><a href="https://wangyujie.space/TDA4VM4/">TDA4④：部署自定义模型</a></p>
</blockquote>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
              <a href="/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/" rel="tag"># 嵌入式</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/DLdeploy/" rel="prev" title="DL模型转换及部署：torch > onnx > deploy">
      <i class="fa fa-chevron-left"></i> DL模型转换及部署：torch > onnx > deploy
    </a></div>
      <div class="post-nav-item">
    <a href="/TDA4VM4/" rel="next" title="TDA4④：部署自定义深度学习模型">
      TDA4④：部署自定义深度学习模型 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#YOLOX%E9%83%A8%E7%BD%B2TDA4VM-SK%E6%B5%81%E7%A8%8B"><span class="nav-number">1.</span> <span class="nav-text">YOLOX部署TDA4VM-SK流程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E4%BD%BF%E7%94%A8edgeai-yolox%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.1.</span> <span class="nav-text">1. 使用edgeai-yolox训练模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6%E8%BD%ACONNX"><span class="nav-number">1.2.</span> <span class="nav-text">2. 模型文件转ONNX</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2"><span class="nav-number">1.3.</span> <span class="nav-text">3. 模型转换</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#a-%E4%BD%BF%E7%94%A8TIDL-Importer-in-RTOS-SDK"><span class="nav-number">1.3.1.</span> <span class="nav-text">a. 使用TIDL Importer (in RTOS SDK)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#b-%E4%BD%BF%E7%94%A8Edge-AI-Studio"><span class="nav-number">1.3.2.</span> <span class="nav-text">b. 使用Edge AI Studio</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#c-%E4%BD%BF%E7%94%A8EdgeAI-TIDL-Tools"><span class="nav-number">1.3.3.</span> <span class="nav-text">c. 使用EdgeAI-TIDL-Tools</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E6%9D%BF%E7%AB%AF%E8%BF%90%E8%A1%8C-TDA4VM-SK"><span class="nav-number">1.4.</span> <span class="nav-text">4. 板端运行(TDA4VM-SK)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9app-edgeai%EF%BC%88optional%EF%BC%89"><span class="nav-number">1.4.1.</span> <span class="nav-text">修改app_edgeai（optional）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0"><span class="nav-number">1.5.</span> <span class="nav-text">5. 性能评估</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Performance-Logs"><span class="nav-number">2.</span> <span class="nav-text">Performance Logs</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary-of-CPU-load"><span class="nav-number">2.1.</span> <span class="nav-text">Summary of CPU load</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HWA-performance-statistics"><span class="nav-number">2.2.</span> <span class="nav-text">HWA performance statistics</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DDR-performance-statistics"><span class="nav-number">2.3.</span> <span class="nav-text">DDR performance statistics</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Detailed-CPU-performance-memory-statistics"><span class="nav-number">2.4.</span> <span class="nav-text">Detailed CPU performance&#x2F;memory statistics</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU-mcu2-0"><span class="nav-number">2.4.1.</span> <span class="nav-text">CPU: mcu2_0</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CPU-Heap-Table"><span class="nav-number">2.4.1.1.</span> <span class="nav-text">CPU Heap Table</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU-mcu2-1"><span class="nav-number">2.4.2.</span> <span class="nav-text">CPU: mcu2_1</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CPU-Heap-Table-1"><span class="nav-number">2.4.2.1.</span> <span class="nav-text">CPU Heap Table</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU-c6x-1"><span class="nav-number">2.4.3.</span> <span class="nav-text">CPU: c6x_1</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CPU-Heap-Table-2"><span class="nav-number">2.4.3.1.</span> <span class="nav-text">CPU Heap Table</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU-c6x-2"><span class="nav-number">2.4.4.</span> <span class="nav-text">CPU: c6x_2</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CPU-Heap-Table-3"><span class="nav-number">2.4.4.1.</span> <span class="nav-text">CPU Heap Table</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU-c7x-1"><span class="nav-number">2.4.5.</span> <span class="nav-text">CPU: c7x_1</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CPU-Heap-Table-4"><span class="nav-number">2.4.5.1.</span> <span class="nav-text">CPU Heap Table</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Performance-point-statistics"><span class="nav-number">2.5.</span> <span class="nav-text">Performance point statistics</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Performance"><span class="nav-number">2.5.1.</span> <span class="nav-text">Performance</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#FPS"><span class="nav-number">2.5.2.</span> <span class="nav-text">FPS</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Temperature-statistics"><span class="nav-number">2.6.</span> <span class="nav-text">Temperature statistics</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Arrow</p>
  <div class="site-description" itemprop="description">记录一些杂七杂八的东西</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Arrowes" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Arrowes" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:395841716@qq.com" title="E-Mail → mailto:395841716@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/wangyujie.site" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;wangyujie.site" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>Zhihu</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/Arrowes?spm=1000.2115.3001.5343" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;Arrowes?spm&#x3D;1000.2115.3001.5343" rel="noopener" target="_blank"><i class="fa fa-crosshairs fa-fw"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/23930762?spm_id_from=333.1007.0.0" title="bilibili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;23930762?spm_id_from&#x3D;333.1007.0.0" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>bilibili</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://oshwhub.com/arrows" title="立创EDA → https:&#x2F;&#x2F;oshwhub.com&#x2F;arrows" rel="noopener" target="_blank"><i class="fa fa-microchip fa-fw"></i>立创EDA</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Arrow</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">92k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">5:33</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  
  <script data-pjax>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="/js/local-search.js"></script>











<script data-pjax>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'dark',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '0cf14e51c1582cf64289',
      clientSecret: '5e8273d27714e40495267c73e607cfe9322b7266',
      repo        : 'Arrowes.github.io',
      owner       : 'Arrowes',
      admin       : ['Arrowes'],
      id          : 'eff9cf46dfeefbb1e41c216c4f65c367',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

    </div>
</body>
</html>
