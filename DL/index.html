<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/128.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/16.png">
  <link rel="mask-icon" href="/images/arrow.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wangyujie.space","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"default"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":true,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="记录深度学习基本概念，不断更新中，项目地址：DLpractice">
<meta property="og:type" content="article">
<meta property="og:title" content="DL：深度学习相关概念">
<meta property="og:url" content="https://wangyujie.space/DL/index.html">
<meta property="og:site_name" content="Arrow的笔记本">
<meta property="og:description" content="记录深度学习基本概念，不断更新中，项目地址：DLpractice">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL1.png">
<meta property="og:image" content="https://zh.d2l.ai/_images/output_mlp_76f463_51_0.svg">
<meta property="og:image" content="https://zh.d2l.ai/_images/output_mlp_76f463_81_0.svg">
<meta property="og:image" content="https://zh.d2l.ai/_images/output_mlp_76f463_21_0.svg">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL_ELU.png">
<meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMyLnpoaW1nLmNvbS84MC92Mi02MDRiZTExNGZhMDQ3OGYzYTEwNTk5MjNmZDEwMjJkMV9oZC5wbmc?x-oss-process=image/format,png">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-93a99cd695aeb1b8edf0c4b4eac8b7a9_1440w.webp?source=1940ef5c">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL2.png">
<meta property="og:image" content="https://pic1.zhimg.com/50/v2-d552433faa8363df84c53b905443a556_720w.webp?source=1940ef5c">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL-Conv.jpg">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL3.gif">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL4.png">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL5.png">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL6.png">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL7.png">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL8.png">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL9.png">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL10.png">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL11ROC.jpg">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL12AUC.png">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL13.png">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL14.png">
<meta property="og:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL15.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/direct/dbf3bfb8a37c4c1582d09b9ebd6ad01b.png#pic_center">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/480474efbee3b54d014a3f6691284354.jpeg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-c4e6229a1fd42692d090108481be34a6_1440w.webp">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-2463639f7e39afd273fdeccbfa530d49_1440w.webp">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-d7eb7e24335613da3da22da4ea93e132_1440w.webp">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-7ecc8e5e19c59a3e6682c5e3cdc34918_1440w.webp">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-5d614997aa85e1b841457094b7bc0cbb_1440w.webp">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-b03d43ed4b3dc4c02e68712e57023cff_1440w.webp">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-0d17b53f68286931803bf9d1dca10467_1440w.webp">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-ba9edb24f8cbf10ee77bacb7f10befa7_1440w.webp">
<meta property="article:published_time" content="2022-12-28T12:22:05.000Z">
<meta property="article:modified_time" content="2025-05-05T15:25:10.437Z">
<meta property="article:author" content="Arrow">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL1.png">

<link rel="canonical" href="https://wangyujie.space/DL/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>DL：深度学习相关概念 | Arrow的笔记本</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Arrow的笔记本" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Arrow的笔记本</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <a>
        <img class="custom-logo-image" src="/images/arrow.png" alt="Arrow的笔记本">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="https://wangyujie.space/pintree/" rel="section"><i class="fa fa-sitemap fa-fw"></i>书签</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wangyujie.space/DL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Arrow">
      <meta itemprop="description" content="记录一些杂七杂八的东西">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Arrow的笔记本">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          DL：深度学习相关概念
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-28 20:22:05" itemprop="dateCreated datePublished" datetime="2022-12-28T20:22:05+08:00">2022-12-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-05-05 23:25:10" itemprop="dateModified" datetime="2025-05-05T23:25:10+08:00">2025-05-05</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>9.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>35 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>记录深度学习基本概念，不断更新中，项目地址：<a target="_blank" rel="noopener" href="https://github.com/Arrowes/DLpractice">DLpractice</a></p>
<span id="more"></span>

<p>从机器学习到深度学习：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/subconscious/p/4107357.html">从机器学习谈起</a>，<a target="_blank" rel="noopener" href="https://www.cnblogs.com/subconscious/p/5058741.html">从神经元到深度学习</a><br>什么是卷积讲解视频：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1sb411P7pQ/?share_source=copy_web&vd_source=b148fb6f311bfe6f3870ad8f4dfda92a">大白话讲解卷积神经网络工作原理</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/scutan90/DeepLearning-500-questions">DL500问</a></p>
<h1 id="深度学习框架"><a href="#深度学习框架" class="headerlink" title="深度学习框架"></a>深度学习框架</h1><pre class="mermaid">graph LR
A[程序框架]-->B[A.黑箱]
A-->C[B.模块化] -->1.处理数据
C-->2.构建网络
C-->3.损失函数
C-->4.优化函数
C-->5.模型保存
A-->E[C.定义]</pre>

<img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL1.png" width = "60%" />

<p>GPU 网络和数据要同时送进GPU</p>
<h2 id="激活函数-Activate-Function"><a href="#激活函数-Activate-Function" class="headerlink" title="激活函数 Activate Function"></a>激活函数 Activate Function</h2><p>激活函数是深度学习神经网络中的一个重要组成部分，它用来引入<em>非线性性质</em>，使神经网络能够学习复杂的函数关系。激活函数接收神经元的输入，并产生输出作为下一层神经元的输入。在神经网络中，激活函数通常被应用于每个神经元的输出，使神经网络能够进行非线性映射和学习。</p>
<p>激活函数的主要作用有以下几点：</p>
<ul>
<li>非线性映射：激活函数引入非线性性质，使神经网络可以逼近和表示复杂的非线性函数。如果没有激活函数，多层神经网络的组合将等效于单一层的线性变换。</li>
<li>特征提取：激活函数有助于神经网络从输入数据中提取关键特征，例如边缘、纹理、形状等，以便更好地完成分类、回归和其他任务。</li>
<li>解决梯度消失问题：某些激活函数（如ReLU）有助于减轻梯度消失问题，使深层网络能够更好地进行反向传播和训练。</li>
</ul>
<p>一些常见的激活函数包括：</p>
<table>
<thead>
<tr>
<th>激活函数</th>
<th>特点</th>
<th>图像</th>
</tr>
</thead>
<tbody><tr>
<td>$$softmax(x_i) &#x3D; \frac{e^{x_i}}{\sum_{j&#x3D;0}^{N} e^{x_j}}$$</td>
<td>将未规范化的预测变换为非负数并且总和为1，同时让模型保持可导的性质;常用在分类网络的最后一层，把网络输出转化为各类别的概率。</td>
<td>首先对每个未规范化的预测求幂，这样可以确保输出非负。为了确保最终输出的概率值总和为1，再让每个求幂后的结果除以它们的总和</td>
</tr>
<tr>
<td>挤压函数（squashing function）$$sigmoid(x) &#x3D; \frac 1{1 + exp(−x)}$$</td>
<td>将输入映射到范围(0, 1)，常用于二元分类问题。sigmoid可以视为softmax的特例</td>
<td><img data-src="https://zh.d2l.ai/_images/output_mlp_76f463_51_0.svg"  /></td>
</tr>
<tr>
<td>双曲正切 $$tanh(x) &#x3D; \frac {1 − exp(−2x)}{1 + exp(−2x)}$$</td>
<td>将输入映射到范围(-1, 1)，也用于某些分类和回归问题, 当输入在0附近时，tanh函数接近线性变换。形状类似于sigmoid函数，不同的是tanh函数关于坐标系原点中心对称。（LSTM）</td>
<td><img data-src="https://zh.d2l.ai/_images/output_mlp_76f463_81_0.svg"  /></td>
</tr>
<tr>
<td>修正线性单元（Rectified Linear Unit）$$ReLU(x) &#x3D; max(x, 0)$$  $$LeakyReLU&#x3D;max(αx,x)$$</td>
<td>求导表现得特别好：要么让参数消失，要么让参数通过。最常用的激活函数，通常能够加速收敛和减轻梯度消失问题（Transfromer）； LeakyReLU中通常设α&#x3D;0.01来调整负值的零梯度，缓解dead ReLU问题（YOLO） 若α为可学习参数，则为PReLU</td>
<td><img data-src="https://zh.d2l.ai/_images/output_mlp_76f463_21_0.svg"  /></td>
</tr>
<tr>
<td>指数线性单元 (Exponential Linear Units) <img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL_ELU.png"/></td>
<td>对小于零的情况采用类似指数计算的方式进行输出。与 ReLU 相比，ELU 有负值，这会使激活的平均值接近零。均值激活接近于零可以使学习更快，因为它们使梯度更接近自然梯度。但计算量较大</td>
<td><img data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMyLnpoaW1nLmNvbS84MC92Mi02MDRiZTExNGZhMDQ3OGYzYTEwNTk5MjNmZDEwMjJkMV9oZC5wbmc?x-oss-process=image/format,png"  /></td>
</tr>
</tbody></table>
<h2 id="感受野-Receptive-field"><a href="#感受野-Receptive-field" class="headerlink" title="感受野(Receptive field)"></a>感受野(Receptive field)</h2><p>感受野是指在卷积神经网络中，输出特征图上的一个像素点对应于输入图像上的感受区域大小。感受野的大小可以用来衡量网络在某一层上能够“看到”输入图像的范围，从而影响网络对局部和全局信息的感知能力。<br><img data-src="https://pic1.zhimg.com/80/v2-93a99cd695aeb1b8edf0c4b4eac8b7a9_1440w.webp?source=1940ef5c"  /></p>
<p>$   n_{output.features}&#x3D;[\frac{n_{input.features}+2p_{adding.size}-k_{ernel.size}}{s_{tride.size}}+1]   $<br>较小的感受野通常用于捕获局部特征，而较大的感受野则有助于捕获全局信息。<br><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL2.png" width = "50%" /></p>
<img data-src="https://pic1.zhimg.com/50/v2-d552433faa8363df84c53b905443a556_720w.webp?source=1940ef5c" width = "20%" />

<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><img alt="图 37" data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL-Conv.jpg" />  


<h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p>待续</p>
<h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL3.gif" width = "60%" />

<p>$$SGD → SGDM → NAG → AdaGrad → AdaDelta → Adam → Nadam$$<br><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL4.png" alt="图 4">  </p>
<h2 id="Batch-size"><a href="#Batch-size" class="headerlink" title="Batch size"></a>Batch size</h2><p>batch size的大小影响的是训练过程中的完成<em>每个epoch所需的时间</em> $^1$（假设算力确定了）和每次迭代(iteration)之间<em>梯度的平滑程度</em> $^2$。</p>
<blockquote>
<ol>
<li>假设训练集大小为N，每个epoch中mini-batch大小为b，那么完成每个epoch所需的迭代次数为 N&#x2F;b , 因此完成每个epoch所需的时间会随着迭代次数的增加而增加</li>
<li>如pytorch\tensorflow等深度学习框架，在进行mini-batch的loss反向传播时，一般都是先将每个mini-batch中每个样本得到的loss求sum后再平均化之后再反求梯度，进行迭代，因此b的大小决定了相邻迭代batch之间的梯度平滑程度。一个batch内所含样本越多，这个batch的梯度应该越能反映真实的梯度，因此这样的大batch间梯度不会跨越太大</li>
</ol>
</blockquote>
<p>因此：大的batch_size往往建议可以相应取大点learning_rate, 因为梯度震荡小，大 learning_rate可以加速收敛过程，也可以防止陷入到局部最小值，而小batch_size用小learning_rate迭代，防止错过最优点，一直上下震荡没法收敛 </p>
<blockquote>
<ol>
<li>若是loss还能降，指标还在升，那说明欠拟合，还没收敛，应该继续train，增大epoch。</li>
<li>若是loss还能再降，指标也在降，说明过拟合了，那就得采用提前终止（减少epoch）或采用weight_decay等防过拟合措施。</li>
<li>若是设置epoch&#x3D;16，到第8个epoch，loss也不降了，指标也不动了，说明8个epoch就够了，剩下的白算了。</li>
</ol>
</blockquote>
<h2 id="损失函数「loss-function」"><a href="#损失函数「loss-function」" class="headerlink" title="损失函数「loss function」"></a>损失函数「loss function」</h2><p>来度量模型的预测值$\hat{y}$与真实值$y$的差异程度的运算函数，它是一个非负实值函数，通常使用$L(y, \hat{y})$来表示，损失函数越小，模型的鲁棒性就越好。</p>
<h3 id="基于距离度量的损失函数"><a href="#基于距离度量的损失函数" class="headerlink" title="基于距离度量的损失函数"></a>基于距离度量的损失函数</h3><p>基于距离度量的损失函数通常将输入数据映射到基于距离度量的特征空间上，如欧氏空间、汉明空间等，将映射后的样本看作空间上的点，采用合适的损失函数度量特征空间上样本真实值和模型预测值之间的距离。特征空间上两个点的距离越小，模型的预测性能越好。<br><strong>L1范数损失函数（MAE）</strong><br>$$L_{MSE}&#x3D;\frac{1}{n}\sum_{i&#x3D;1}^{n}|y_i-\hat{y_i}|$$<br>又称为曼哈顿距离，表示残差的绝对值之和。L1损失函数对离群点有很好的鲁棒性，但它在残差为零处却不可导,且更新的梯度始终相同；<br><strong>L2损失函数（MSE均方误差损失函数）</strong><br>$$L_{MSE}&#x3D;\frac{1}{n}\sum_{i&#x3D;1}^{n}(y_i-\hat{y_i})^2$$<br>在回归问题中，均方误差损失函数用于度量样本点到回归曲线的距离，通过最小化平方损失使样本点可以更好地拟合回归曲线。（L2损失又被称为欧氏距离，是一种常用的距离度量方法，通常用于度量数据点之间的相似度。）</p>
<h3 id="基于概率分布度量的损失函数"><a href="#基于概率分布度量的损失函数" class="headerlink" title="基于概率分布度量的损失函数"></a>基于概率分布度量的损失函数</h3><p>基于概率分布度量的损失函数是将样本间的相似性转化为随机事件出现的可能性，即通过度量样本的真实分布与它估计的分布之间的距离，判断两者的相似度，一般用于涉及概率分布或预测类别出现的概率的应用问题中，在分类问题中尤为常用。<br><strong>KL散度（ Kullback-Leibler divergence）</strong><br>$$L_{MSE}&#x3D;\sum_{i&#x3D;1}^{n}\hat{y_i}log(\frac{y_i}{\hat{y_i}})$$<br>也被称为相对熵，是一种非对称度量方法，常用于度量两个概率分布之间的距离。KL散度也可以衡量两个随机分布之间的距离，两个随机分布的相似度越高的，它们的KL散度越小，可以用于比较文本标签或图像的相似性。<br><strong>交叉熵损失函数「Cross Entropy Loss」</strong><br>$$L&#x3D;-[ylog\hat{y}+(1-y)log(1-\hat{y})]$$<br>$$L&#x3D;\sum_{i&#x3D;1}^{N}y^ilog\hat{y}^i+(1-y^i)log(1-\hat{y}^i)$$<br>交叉熵是信息论中的一个概念，最初用于估算平均编码长度，引入机器学习后，用于评估当前训练得到的概率分布与真实分布的差异情况。为了使神经网络的每一层输出从线性组合转为非线性逼近，以提高模型的预测精度，在以交叉熵为损失函数的神经网络模型中一般选用tanh、sigmoid、softmax或ReLU作为激活函数。</p>
<p>交叉熵损失函数刻画了实际输出概率与期望输出概率之间的相似度，也就是交叉熵的值越小，两个概率分布就越接近，特别是在正负样本不均衡的分类问题中，常用交叉熵作为损失函数。目前，交叉熵损失函数是卷积神经网络中最常使用的分类损失函数，它可以有效避免梯度消散。在二分类情况下也叫做对数损失函数</p>
<p>在多分类任务中，经常采用 softmax 激活函数+交叉熵损失函数，因为交叉熵描述了两个概率分布的差异，然而神经网络输出的是向量，并不是概率分布的形式。所以需要 softmax激活函数将一个向量进行“归一化”成概率分布的形式，再采用交叉熵损失函数计算 loss。</p>
<p>在Pytorch中，BCELoss和BCEWithLogitsLoss是一组常用的二元交叉熵损失函数，常用于二分类问题。区别在于BCELoss的输入需要先进行Sigmoid处理，而BCEWithLogitsLoss则是将Sigmoid和BCELoss合成一步，也就是说BCEWithLogitsLoss函数内部自动先对output进行Sigmoid处理，再对output 和target进行BCELoss计算。 </p>
<p>one-hot独热编码：将类别变量转换为机器学习算法易于利用的一种形式的过程。</p>
<h1 id="注意力机制（Attention-Mechanism）"><a href="#注意力机制（Attention-Mechanism）" class="headerlink" title="注意力机制（Attention Mechanism）"></a>注意力机制（Attention Mechanism）</h1><p>自上而下有意识的聚焦称为<strong>聚焦式注意力</strong>，自下而上无意识、由外界刺激引发的注意力称为<strong>显著式注意力</strong>。<br>神经网络中的注意力机制是在计算能力有限的情况下，将计算资源分配给更重要的任务，同时解决信息超载问题的一种资源分配方案，到2014年，Volodymyr的《Recurrent Models of Visual Attention》一文中将其应用在视觉领域，后来伴随着2017年Ashish Vaswani的《Attention is all you need》中Transformer结构的提出，注意力机制在NLP,CV相关问题的网络设计上被广泛应用。<br>注意力有两种，一种是软注意力(soft attention)，另一种则是强注意力(hard attention)。<br><strong>软注意力</strong>更关注区域或者通道，是确定性的注意力，学习完成后直接可以通过网络生成，最关键的地方是软注意力是可微的，这是一个非常重要的地方。可以微分的注意力就可以通过神经网络算出梯度并且前向传播和后向反馈来学习得到注意力的权重。<br><strong>强注意力</strong>是更加关注点，也就是图像中的每个点都有可能延伸出注意力，同时强注意力是一个随机的预测过程，更强调动态变化。当然，最关键是强注意力是一个不可微的注意力，训练过程往往是通过增强学习(reinforcement learning)来完成的。</p>
<h2 id="软注意力的注意力域"><a href="#软注意力的注意力域" class="headerlink" title="软注意力的注意力域"></a>软注意力的注意力域</h2><h3 id="空间域（Spatial-Domain）"><a href="#空间域（Spatial-Domain）" class="headerlink" title="空间域（Spatial Domain）"></a>空间域（Spatial Domain）</h3><p>空间域将原始图片中的空间信息变换到另一个空间中并保留了关键信息。<br>普通的卷积神经网络中的池化层（pooling layer）直接用一些max pooling 或者average pooling 的方法，将图片信息压缩，减少运算量提升准确率。<br>发明者认为之前pooling的方法太过于暴力，直接将信息合并会导致关键信息无法识别出来，所以提出了一个叫 <strong>空间转换器（spatial transformer）</strong> 的模块，将图片中的的空间域信息做对应的空间变换，从而能将关键的信息提取出来。<br><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL5.png" width = "50%" /></p>
<h3 id="通道域（Channel-Domain）"><a href="#通道域（Channel-Domain）" class="headerlink" title="通道域（Channel Domain）"></a>通道域（Channel Domain）</h3><p>通道注意力机制在计算机视觉中，更关注特征图中channel之间的关系，而普通的卷积会对通道做通道融合，这个开山鼻祖是SENet,后面有GSoP-Net，FcaNet 对SENet中的squeeze部分改进，EACNet对SENet中的excitation部分改进，SRM,GCT等对SENet中的scale部分改进。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1709.01507">SENet</a>,<a target="_blank" rel="noopener" href="https://github.com/moskomule/senet.pytorch">pytorch</a><br>SENet《Squeeze-and-Excitation Networks》是CVPR17年的一篇文章，提出SE module。在卷积神经网络中，卷积操作更多的是关注感受野，在通道上默认为是所有通道的融合（深度可分离卷积不对通道进行融合，但是没有学习通道之间的关系，其主要目的是为了减少计算量），SENet提出SE模块，将注意力放到通道之间，希望模型可以学习到不同通道之间的权重：<br><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL6.png" alt="图 6">  </p>
<h3 id="时域注意力机制"><a href="#时域注意力机制" class="headerlink" title="时域注意力机制"></a>时域注意力机制</h3><p>时域注意力机制在cv领域主要考虑有时序信息的领域，如视频领域中的动作识别方向，其注意力机制主要是在时序列中，关注某一时序即某一帧的信息。</p>
<h3 id="通道和空间注意力机制"><a href="#通道和空间注意力机制" class="headerlink" title="通道和空间注意力机制"></a>通道和空间注意力机制</h3><p>通道和空间注意力是基于通道注意力和空间注意力机制，将两者有效的结合在一起，让注意力能关注到两者，又称混合注意力机制，如CBAM,BAM,scSE等，同时基于混合注意力机制的一些关注点，如Triplet Attention 关注各种跨维度的相互作用；Coordinate Attention, DANet关注长距离的依赖；RGA 关注关系感知注意力。还有一种混合注意力机制，为3D的attention :Residual attention,SimAM, Strip Pooling, SCNet等。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1807.06521">CBAM</a>,<a target="_blank" rel="noopener" href="https://github.com/luuuyi/CBAM.PyTorch">github</a><br>CBAM (Convolutional Block Attention Module)是SENet的一种拓展，SENet主要基于通道注意力，CBAM是通道注意力和空间注意力融合的注意力机制。<br><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL7.png" alt="图 7"><br>如上图所示，输入一个h<em>w</em>c的特征图，通过channel Attention Module 生成通道注意力权重对输入特征图在通道层添加权重，再通过spatial Attention Module 生成空间注意力权重，对特征图在空间层添加权重，输出特征图。</p>
<h1 id="Metrics-评估"><a href="#Metrics-评估" class="headerlink" title="Metrics 评估"></a>Metrics 评估</h1><h2 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h2><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL8.png" width = "70%" />

<p>X横坐标为正确的分类（即你用标签所标注的真实分类）<br>Y纵坐标为模型所预测的分类（即图片经过模型推理后模型将其辨别为的分类）</p>
<blockquote>
<p>True positives (TP): 猫🐱的图片被正确识别成了猫🐱。（猫🐱的正确分类预测）<br>True negatives(TN): 背景的图片被正确识别为背景。（非猫🐱被预测为其他动物或背景）<br>False positives(FP): 背景的图片被错误识别为猫🐱。（非猫🐱被预测为猫🐱）<br>False negatives(FN): 猫🐱的图片被错误识别为背景。（猫🐱被预测为其他动物或者背景）</p>
</blockquote>
<h2 id="Evaluation-parameters"><a href="#Evaluation-parameters" class="headerlink" title="Evaluation parameters"></a>Evaluation parameters</h2><p><strong>准确率 Accuracy</strong>：在正负样本数量接近的情况下，准确率越高，模型的性能越好（当测试样本不平衡时，该指标会失去意义。）<br>$$Accuracy&#x3D;\frac{TP+TN}{TP+FP+TN+FN}$$<br><strong>精准率（查准率） precision</strong>：代表在总体预测结果中真阳性的预测数，针对预测结果，当区分能力强时，容易将部分（与负样本相似度高）正样本排除。<br>$$precision(P)&#x3D;\frac{TP}{TP+FP}$$<br><strong>召回率（查全率） recall</strong>：所有ground truths中真阳性的预测数，针对原样本，当敏感度高时，容易将部分（与正样本相似度高）负样本也判断为正样本。<br>$$recall(R)&#x3D;\frac{TP}{TP+FN}$$<br><strong>F1 score</strong>：对Precision和Recall两个指标的调和平均值（类似平均速度），F1分值越高，目标检测的准确性越好。F1-score最常用于数据集的类别不平衡的情况。<br>$$F_1 score&#x3D;2\cdot \frac{P\cdot R}{P+R}$$<br><strong>AP</strong>：同时考察Precision和Recall两个指标来衡量模型对于各个类别的性能。<br>$$AP_i&#x3D;\int_0^1P_i(R_i)dR_i$$<br><strong>mAP</strong>：表示AP的平均值，并用作衡量目标检测算法的总体检测精度的度量。<br>将recall设置为横坐标，precision设置为纵坐标。PR曲线下围成的面积即AP，所有类别AP平均值即mAP.<br>$$mAP&#x3D;\frac1n\sum_{i &#x3D; 1}^{n}AP_i$$<br><strong>置信度 Confidence</strong>：置信度设定越大，Prediction约接近1，Recall越接近0，要寻找最优的F1分数，需要遍历置信度。<br><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL9.png" alt="图 9">  </p>
<p><strong>交并比 IoU</strong>（Intersection over Union）：是目标检测中使用的一个概念，IoU计算的是“预测的边框”和“真实的边框”的交叠率，即它们的交集和并集的比值。最理想情况是完全重叠，即比值为1。</p>
<p><em><a href="mailto:&#x6d;&#97;&#x70;&#64;&#48;&#46;&#53;">&#x6d;&#97;&#x70;&#64;&#48;&#46;&#53;</a></em>即IoU&#x3D;0.5，预测框和标注框的交集与非交集占比相同，都为50%；<br><em>mAP@.5:.95</em>表示在不同IoU阈值（从0.5到0.95，步长0.05）（0.5、0.55、0.6、0.65、0.7、0.75、0.8、0.85、0.9、0.95）上的平均mAP。<br><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL10.png" width = "60%" /></p>
<p><strong>NMS</strong>（Non-Maximum Suppression，非极大值抑制）<br>一种用于目标检测任务的后处理技术，主要用于消除冗余的检测框，保留最可能准确的预测结果。<br>在目标检测中，模型（如YOLO、Faster R-CNN等）通常会对同一目标生成多个重叠的预测框（Bounding Box），每个框带有置信度分数。NMS通过筛选，保留置信度最高且位置最合理的框，抑制其他冗余的框，从而避免重复检测。</p>
<ol>
<li>按置信度排序：将所有预测框按置信度从高到低排序。选择最高置信度的框：取出当前列表中置信度最高的框，加入最终保留列表。</li>
<li>计算IoU并抑制重叠框：计算该框与剩余所有框的交并比（IoU，Intersection over Union）。若某框与当前框的IoU超过设定的阈值（如0.5），则认为它们是同一目标，直接删除。</li>
<li>重复步骤2<del>3：对剩余框重复上述过程，直到所有框被处理。<br>IoU阈值：通常设为0.3</del>0.7，控制框的重叠容忍度。阈值越低，抑制越严格。<br>置信度阈值：预过滤掉低置信度的框（例如只保留置信度≥0.5的框）。</li>
</ol>
<p><strong>ROC曲线</strong>(Receiver Operating Characteristic 受试者工作特征)<br>$$TPR&#x3D;\frac{TP}{TP+FN},FPR&#x3D;\frac{FP}{FP+TN}$$可以理解为分类器对正样本的覆盖敏感性和对负样本的敏感性的权衡。<br>在ROC曲线图中，每个点以对应的FPR值为横坐标，以TPR值为纵坐标<br><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL11ROC.jpg" width = "40%" /></p>
<p><strong>AUC值</strong>：PR曲线下方的面积<br><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL12AUC.png" width = "70%" /></p>
<blockquote>
<p>1.AUC &#x3D; 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。<br>2.0.5 &lt; AUC &lt; 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。<br>3.AUC &#x3D; 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。<br>4.AUC &lt; 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。</p>
</blockquote>
<p>ROC曲线图中，越靠近(0,1)的点对应的模型分类性能越好。而且可以明确的一点是，ROC曲线图中的点对应的模型，它们的不同之处仅仅是在分类时选用的阈值(Threshold)不同，每个点所选用的阈值都对应某个样本被预测为正类的概率值。</p>
<h2 id="模型计算量-FLOPs-和参数量-Params"><a href="#模型计算量-FLOPs-和参数量-Params" class="headerlink" title="模型计算量(FLOPs)和参数量(Params)"></a>模型计算量(FLOPs)和参数量(Params)</h2><p><strong>计算量 FLOPs</strong>：FLOP时指浮点运算次数，s是指秒，即每秒浮点运算次数的意思，考量一个网络模型的计算量的标准。硬件要求是在于芯片的floaps（指的是gpu的运算能力）<br><strong>参数量 Params</strong>：是指网络模型中需要训练的参数总数。硬件要求在于显存大小<br>1.<strong>卷积层</strong><br>计算时间复杂度(计算量)<br>$$Time\sim O(\sum_{l&#x3D;1}^D M_l^2\cdot K_l^2\cdot C_{l-1}\cdot C_l)$$</p>
<p>计算空间复杂度(参数量)<br>$$Space\sim O(\sum_{l&#x3D;1}^D K_l^2\cdot C_{l-1}\cdot C_l+\sum_{l&#x3D;1}^D M^2\cdot C_l)$$</p>
<figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">参数量</span><br><span class="line">(kernel*kernel) *channel_input*channel_output</span><br><span class="line">kernel*kernel 就是 weight * weight</span><br><span class="line">其中kernel*kernel ＝ <span class="number">1</span>个<span class="built_in">feature</span>的参数量</span><br><span class="line"></span><br><span class="line">计算量</span><br><span class="line">(kernel*kernel*<span class="built_in">map</span>*<span class="built_in">map</span>) *channel_input*channel_output</span><br><span class="line">kernel*kernel 就是weight*weight</span><br><span class="line"><span class="built_in">map</span>*<span class="built_in">map</span>是下个featuremap的大小，也就是上个weight*weight到底做了多少次运算</span><br><span class="line">其中kernel*kernel*<span class="built_in">map</span>*<span class="built_in">map</span>＝　<span class="number">1</span>个<span class="built_in">feature</span>的计算量</span><br></pre></td></tr></table></figure>
<p>2.池化层<br>无参数<br>3.<strong>全连接层</strong><br><code>参数量＝计算量＝weight_in*weight_out  #模型里面最费参数的就是全连接层</code></p>
<p><strong>换算计算量</strong>,一般一个参数是指一个float，也就是４个字节,1kb&#x3D;1024字节</p>
<h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><p><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL13.png" alt="图 13"><br><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL14.png" alt="图 14"><br><img data-src="https://raw.gitmirror.com/Arrowes/Blog/main/images/DL15.png" alt="图 15">  </p>
<h1 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h1><h2 id="联邦学习"><a href="#联邦学习" class="headerlink" title="联邦学习"></a>联邦学习</h2><p>联邦学习（Federated Learning）是一种先进的分布式机器学习方法，它在数据隐私保护和数据利用效率方面具有显著的优势。在联邦学习中，多个参与方（也称为客户端或节点）可以在保持数据本地化的同时，共享模型训练的成果。<br>让各个企业自己进行模型的训练，各个企业在完成模型的训练之后，将各自模型的参数上传至一个中心服务器（也可以是点对点），中心服务器结合各个企业的参数（可以上传梯度，也可以是自己更新后的参数），重新拟定新的参数（例如通过加权平均，这一步叫做联邦聚合），将新的参数下发至各个企业，企业将新参数部署到模型上，从而继续新的训练，这个过程可以进行反复的迭代，直到模型收敛，或者满足其他的条件。<br><img data-src="https://i-blog.csdnimg.cn/direct/dbf3bfb8a37c4c1582d09b9ebd6ad01b.png#pic_center" width = "50%" /></p>
<h2 id="分布式训练"><a href="#分布式训练" class="headerlink" title="分布式训练"></a>分布式训练</h2><p>单机单卡情况下，信息都在一台机器上，无所谓分发。而分布式训练中，信息是要被“分发”的，分发的不同方式，常被称为“并行方式”。通常，习惯上将分发方分为“数据并行”和“模型并行”两种：</p>
<ul>
<li>模型并行(Model Parallelism)：将模型进行切分，完整的数据 被送至各个训练节点，与 切分后的模型 进行运算，最后将多个节点的运算结果合并；适用于模型规模大的情况</li>
<li>数据并行(Data Parallelism)：将样本数据进行切分，切分后的数据 被送至各个训练节点，与 完整的模型 进行运算，最后将多个节点的信息进行合并；适用于数据量大的情况<ol>
<li>数据划分：不同GPU设备上划分出不同的mini-batch，作为训练的数据集</li>
<li>前向+反向:不同GPU设备上用相同的模型，用各自接收到的mini-batch数据进行训练（前向和反向传播)</li>
<li>梯度同步更新:每个GPU设备得到了mini-batch训练后的权重值，这些值需要汇总然后更新至每一个GPU设备，保证每一次迭代后，每个GPU设备上的模型完全一致。  <img data-src="https://i-blog.csdnimg.cn/blog_migrate/480474efbee3b54d014a3f6691284354.jpeg" width = "50%" /></li>
</ol>
</li>
</ul>
<blockquote>
<p>分布式训练中的学习率自动缩放：在数据并行中，多个GPU同时处理不同的数据子集（每个GPU的批量大小为 B），总批量大小为 B × GPU数量。例如，单GPU批量大小为256，使用4个GPU时，总批量大小变为1024。<br>更大的批量意味着梯度估计的方差更小，更新方向更准确。为了保持参数更新的有效步长与单GPU训练一致，需要按比例调整学习率。</p>
</blockquote>
<p>分布式系统中因为面临大量的信息同步、更新需求，因此传统的点对点(P2P, Point-to-point)的通信方式不能很好的满足需求。需要使用集合通信库(Collective communication Library)，用于分布式训练时，多个计算设备之间的集合通信，常见的有 Open MPI、NCCL:</p>
<ul>
<li>Open MPI:Open MPI项目是一个开源MPI（消息传递接口 ）实现，由学术，研究和行业合作伙伴联盟开发和维护。因此，Open MPI可以整合高性能计算社区中所有专家，技术和资源，以构建可用的最佳MPI库。</li>
<li>Gloo:facebook开源的一套集体通信库，他提供了对机器学习中有用的一些集合通信算法如：barrier, broadcast, allreduce</li>
<li>NCCL:NVIDIA Collective Communications Library, 英伟达基于NCIDIA-GPU的一套开源的集体通信库，如其官网描述：NVIDIA集体通信库（NCCL）实现了针对NVIDIA GPU性能优化的多GPU和多节点集体通信原语。NCCL提供了诸如all-gather, all-reduce, broadcast, reduce, reduce-scatter等实现，这些实现优化后可以通过PCIe和NVLink等高速互联，从而实现高带宽和低延迟。 因为NCCL则是NVIDIA基于自身硬件定制的，能做到更有针对性且更方便优化，故在英伟达硬件上，NCCL的效果往往比其它的通信库更好。<ul>
<li>P2P（Peer-to-Peer）是指单个节点内的 GPU 之间直接通信，而不需要通过 CPU 或系统内存中转，可以显著提高通信效率。但若某些 GPU 之间没有直接的 P2P 连接（NVLink 或 PCIe P2P），NCCL可能会初始化后挂死，通过设置 NCCL_P2P_DISABLE&#x3D;1，可以强制 NCCL 使用系统内存中转的方式代替 P2P 通信，从而避免这些问题。</li>
</ul>
</li>
</ul>
<p>NCCL遇到显卡P2P通信问题:<a target="_blank" rel="noopener" href="https://huo.zai.meng.li/p/vllm%E5%90%AF%E5%8A%A8%E6%97%B6nccl%E9%81%87%E5%88%B0%E6%98%BE%E5%8D%A1p2p%E9%80%9A%E4%BF%A1%E9%97%AE%E9%A2%98/">1</a> <a target="_blank" rel="noopener" href="https://huo.zai.meng.li/p/vllm%E5%90%AF%E5%8A%A8%E6%97%B6nccl%E9%81%87%E5%88%B0%E6%98%BE%E5%8D%A1p2p%E9%80%9A%E4%BF%A1%E9%97%AE%E9%A2%98/">2</a></p>
<h1 id="MMDetection"><a href="#MMDetection" class="headerlink" title="MMDetection"></a>MMDetection</h1><p><a target="_blank" rel="noopener" href="https://mmdetection.readthedocs.io/zh-cn/latest/">MMDetection</a> 由 7 个主要部分组成，apis、structures、datasets、models、engine、evaluation 和 visualization。</p>
<ul>
<li>apis 为模型推理提供高级 API。</li>
<li>structures 提供 bbox、mask 和 DetDataSample 等数据结构。</li>
<li>datasets 支持用于目标检测、实例分割和全景分割的各种数据集。<ul>
<li>transforms 包含各种数据增强变换。</li>
<li>samplers 定义了不同的数据加载器采样策略。</li>
</ul>
</li>
<li>models 是检测器最重要的部分，包含检测器的不同组件。<ul>
<li>detectors 定义所有检测模型类。</li>
<li>data_preprocessors 用于预处理模型的输入数据。</li>
<li>backbones 包含各种骨干网络。</li>
<li>necks 包含各种模型颈部组件。</li>
<li>dense_heads 包含执行密集预测的各种检测头。</li>
<li>roi_heads 包含从 RoI 预测的各种检测头。</li>
<li>seg_heads 包含各种分割头。</li>
<li>losses 包含各种损失函数。</li>
<li>task_modules 为检测任务提供模块，例如 assigners、samplers、box coders 和 prior generators。</li>
<li>layers 提供了一些基本的神经网络层。</li>
</ul>
</li>
<li>engine 是运行时组件的一部分。<ul>
<li>runner 为 MMEngine 的执行器提供扩展。</li>
<li>schedulers 提供用于调整优化超参数的调度程序。</li>
<li>optimizers 提供优化器和优化器封装。</li>
<li>hooks 提供执行器的各种钩子。</li>
</ul>
</li>
<li>evaluation 为评估模型性能提供不同的指标。</li>
<li>visualization 用于可视化检测结果。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://mmdetection.readthedocs.io/zh-cn/latest/get_started.html">文档 - 环境安装与验证</a></p>
<ol>
<li>使用 MIM 安装 MMEngine 和 MMCV。</li>
<li>从源码安装MMDetection</li>
<li>验证<blockquote>
<p>Debug:<br>1.验证推理时报AssertionError: MMCV &#x3D;&#x3D; 2.2.0 is used but incompatible. Please install mmcv&gt;&#x3D;2.0.0rc4, &lt;2.2.0. 解决: mmdet&#x2F;<strong>init</strong>.py”, line 17 强行改版本适配 &lt;&#x3D;<br>2.ModuleNotFoundError: No module named ‘mmdet’ 解决：编译mmdetection：python setup.py develop<br>3.cuda版本问题：conda install pytorch &#x3D;&#x3D; 1.13.1 torchvision &#x3D;&#x3D; 0.14.1 torchaudio&#x3D;&#x3D;0.13.1 cudatoolkit&#x3D;11.7 pytorch-cuda&#x3D;11.7 -c pytorch -c nvidia</p>
</blockquote>
</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://mmdetection.readthedocs.io/zh-cn/latest/user_guides/index.html#id1">训练 &amp; 测试</a>：使用开源模型和数据集来执行常见的训练和测试任务</p>
<p><a target="_blank" rel="noopener" href="https://mmdetection.readthedocs.io/zh-cn/latest/user_guides/index.html#id2">实用工具</a>：</p>
<ul>
<li><p>查看模型配置:<code>python tools/misc/print_config.py ./configs/_base_/models/mask-rcnn_r50_fpn.py</code></p>
</li>
<li><p>列出所有模型：<code>models = DetInferencer.list_models(&#39;mmdet&#39;)</code></p>
</li>
<li><p>推理：推理的高层编程接口——推理器Inferencer</p>
  <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mmdet.apis <span class="keyword">import</span> DetInferencer</span><br><span class="line">inferencer = DetInferencer(<span class="string">&#x27;rtmdet_tiny_8xb32-300e_coco&#x27;</span>)   <span class="comment"># 初始化模型</span></span><br><span class="line">inferencer(<span class="string">&#x27;demo/demo.jpg&#x27;</span>, show=<span class="literal">False</span>,out_dir=<span class="string">&#x27;./outputs&#x27;</span>,print_result=<span class="literal">True</span>)   <span class="comment"># 推理示例图片</span></span><br><span class="line"><span class="comment"># 快速验证：</span></span><br><span class="line">python demo/image_demo.py demo/demo.jpg rtmdet_tiny_8xb32-300e_coco.py --weights rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth --device cpu</span><br></pre></td></tr></table></figure>
</li>
<li><p>下载COCO数据集：<code>python tools/misc/download_dataset.py --dataset-name coco2017</code></p>
</li>
<li><p>测试：<code>python tools/test.py $&#123;CONFIG_FILE&#125; $&#123;CHECKPOINT_FILE&#125; [--out $&#123;RESULT_FILE&#125;] [--show]</code></p>
  <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/test.py configs/rtmdet/rtmdet_l_8xb32-300e_coco.py checkpoints/rtmdet_l_8xb32-300e_coco_20220719_112030-5a0be7c4.pth --show-dir rtmdet_l_8xb32-300e_coco_results</span><br></pre></td></tr></table></figure></li>
<li><p>训练：</p>
  <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python tools/train.py &#123;CONFIG_FILE&#125; [optional arguments]</span><br><span class="line">python tools/train.py configs/retinanet/retinanet_r50_fpn_1x_coco.py</span><br></pre></td></tr></table></figure></li>
<li><p><code>tensorboard --logdir=work_dirs</code>:<br>  tensorboard可视化–在<code>../_base_/default_runtime.py</code>–visualizer中：</p>
  <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vis_backends = [</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;LocalVisBackend&#x27;</span>),</span><br><span class="line">    <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;TensorboardVisBackend&#x27;</span>)</span><br><span class="line">]</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a><a target="_blank" rel="noopener" href="https://mmdetection.readthedocs.io/zh-cn/latest/user_guides/config.html#id1">配置文件</a></h2><p><a target="_blank" rel="noopener" href="https://mmengine.readthedocs.io/zh-cn/latest/advanced_tutorials/config.html">MMEngine - 配置（CONFIG）详细文档</a><br>在 MMDetection 中，一个模型被定义为一个配置文件 和对应被存储在 checkpoint 文件内的模型参数的集合。<br><code>./mmdetection/configs/_base_/..</code><br>在 config&#x2F;<em>base</em> 文件夹下有 4 个基本组件类型，分别是：数据集(dataset)，模型(model)，训练策略(schedule)和运行时的默认设置(default runtime)。许多方法，例如 Faster R-CNN、Mask R-CNN、Cascade R-CNN、RPN、SSD 能够很容易地构建出来。由 <em>base</em> 下的组件组成的配置，被我们称为 原始配置(primitive)。</p>
<ol>
<li>模型配置: 在 mmdetection 的配置中，我们使用 model 字段来配置检测算法的组件。 除了 backbone、neck 等神经网络组件外，还需要 data_preprocessor、train_cfg 和 test_cfg。 data_preprocessor 负责对 dataloader 输出的每一批数据进行预处理。 模型配置中的 train_cfg 和 test_cfg 用于设置训练和测试组件的超参数。</li>
<li>数据集和评测器配置: 在使用执行器 进行训练、测试、验证时，我们需要配置 Dataloader。构建数据 dataloader 需要设置数据集（dataset）和数据处理流程（data pipeline）。 由于这部分的配置较为复杂，我们使用中间变量来简化 dataloader 配置的编写。</li>
<li>训练和测试的配置: MMEngine 的 Runner 使用 Loop 来控制训练，验证和测试过程。 用户可以使用这些字段设置最大训练轮次和验证间隔。</li>
<li>优化相关配置: optim_wrapper 是配置优化相关设置的字段。优化器封装（OptimWrapper）不仅提供了优化器的功能，还支持梯度裁剪、混合精度训练等功能。param_scheduler 字段用于配置参数调度器（Parameter Scheduler）来调整优化器的超参数（例如学习率和动量）。 用户可以组合多个调度器来创建所需的参数调整策略。</li>
<li>钩子配置与运行相关配置：用户可以在训练、验证和测试循环上添加钩子，以便在运行期间插入一些操作。配置中有两种不同的钩子字段，一种是 default_hooks，另一种是 custom_hooks。<br><a target="_blank" rel="noopener" href="https://mmengine.readthedocs.io/zh-cn/latest/tutorials/hook.html">MMEngine - Hook</a></li>
</ol>
<h2 id="进阶教程"><a href="#进阶教程" class="headerlink" title="进阶教程"></a><a target="_blank" rel="noopener" href="https://mmdetection.readthedocs.io/zh-cn/latest/advanced_guides/index.html">进阶教程</a></h2><p>自定义模型重点看：<a target="_blank" rel="noopener" href="https://mmdetection.readthedocs.io/zh-cn/latest/advanced_guides/index.html#id2">组件定制</a></p>
<p>深入理解看：<a target="_blank" rel="noopener" href="https://mmdetection.readthedocs.io/zh-cn/latest/article.html">中文教程</a></p>
<p><a target="_blank" rel="noopener" href="https://mmengine.readthedocs.io/zh-cn/latest/get_started/introduction.html">MMEngine</a>，较深入时要看</p>
<h3 id="算法组件："><a href="#算法组件：" class="headerlink" title="算法组件："></a><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/337375549">算法组件</a>：</h3><p><strong>训练核心组件</strong></p>
<ol>
<li>Backbone: 任何一个 batch 的图片先输入到 backbone 中进行特征提取，典型的骨干网络是 ResNet, Darknet <code>mmdet/models/backbones</code></li>
<li>Neck: 输出的单尺度或者多尺度特征图输入到 neck 模块中进行特征融合或者增强，neck 可以认为是 backbone 和 head 的连接层，主要负责对 backbone 的特征进行高效融合和增强，能够对输入的单尺度或者多尺度特征进行融合、增强输出等。典型的 neck 是 FPN <code>mmdet/models/necks</code></li>
<li>Head: 上述多尺度特征最终输入到 head 部分，一般都会包括分类和回归分支输出;目标检测算法输出一般包括分类和框坐标回归两个分支，不同算法 head 模块复杂程度不一样，灵活度比较高。在网络构建方面，理解目标检测算法主要是要理解 head 模块。<code>mmdet/models/dense_heads + roi_heads</code><br>虽然 head 部分的网络构建比较简单，但是由于正负样本属性定义、正负样本采样和 bbox 编解码模块都在 head 模块中进行组合调用，故 MMDetection 中最复杂的模块就是 head。</li>
<li><ol>
<li>Enhance: 在整个网络构建阶段都可以引入一些即插即用增强算子来增加提取提取能力，典型的例如 SPP、DCN、注意力机制 等等</li>
</ol>
</li>
<li><ol start="2">
<li>BBox Assigner，BBox Sampler：目标检测 head 输出一般是特征图，对于分类任务存在严重的正负样本不平衡，可以通过正负样本属性分配和采样策略控制 <code>mmdet/core/bbox/assigners + samplers</code></li>
</ol>
</li>
<li><ol start="3">
<li>BBox Encoder：为了方便收敛和平衡多分支，一般都会对 gt bbox 进行编码，如归一化 <code>mmdet/core/bbox/coder</code></li>
</ol>
</li>
<li><ol start="4">
<li>Loss: 最后一步是计算分类和回归 loss，进行训练 <code>mmdet/models/losses</code></li>
</ol>
</li>
<li>Training tricks: 在训练过程中也包括非常多的 trick，例如优化器选择等，参数调节也非常关键</li>
</ol>
<p><code>bbox_head.forward_train</code></p>
<p><strong>测试核心组件</strong><br>BBox Decoder：对应Encoder <code>mmdet/core/bbox/coder</code><br>BBox PostProcess：最常用的后处理就是非极大值抑制以及其变种。<code>mmdet/core/post_processing</code><br>Testing tricks：典型的是多尺度测试以及各种模型集成手段</p>
<p><code>bbox_head.get_bboxes</code></p>
<p><img data-src="https://pic3.zhimg.com/80/v2-c4e6229a1fd42692d090108481be34a6_1440w.webp" alt="MM"></p>
<h3 id="整体构建细节"><a href="#整体构建细节" class="headerlink" title="整体构建细节"></a><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/341954021">整体构建细节</a></h3><img data-src="https://pic2.zhimg.com/80/v2-2463639f7e39afd273fdeccbfa530d49_1440w.webp" width = "80%" />

<p>Pipeline: 由一系列按照插入顺序运行的数据处理模块组成，每个模块完成某个特定功能，例如 Resize，因为其流式顺序运行特性，故叫做 Pipeline。<br><img data-src="https://pic3.zhimg.com/80/v2-d7eb7e24335613da3da22da4ea93e132_1440w.webp" alt="pipe"></p>
<p>MMDataParallel:处理Dataloader中pytorch 无法解析的DataContainer 对象,且额外实现了 <code>train_step()</code> 和 <code>val_step() </code>两个函数，可以被 Runner 调用</p>
<p>Model:<br><img data-src="https://pic1.zhimg.com/80/v2-7ecc8e5e19c59a3e6682c5e3cdc34918_1440w.webp" width = "80%" /></p>
<p>Runner:封装了 OpenMMLab 体系下各个框架的训练和验证详细流程，其负责管理训练和验证过程中的整个生命周期，通过预定义回调函数，用户可以插入定制化 Hook ，从而实现各种各样的需求。<br><img data-src="https://pic4.zhimg.com/80/v2-5d614997aa85e1b841457094b7bc0cbb_1440w.webp" width = "90%" /></p>
<p>整体代码抽象<br><img data-src="https://pic4.zhimg.com/80/v2-b03d43ed4b3dc4c02e68712e57023cff_1440w.webp" width = "80%" /></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#=================== tools/train.py ==================</span></span><br><span class="line"><span class="comment"># 1.初始化配置</span></span><br><span class="line">cfg = Config.fromfile(args.config)</span><br><span class="line"><span class="comment"># 2.判断是否为分布式训练模式</span></span><br><span class="line"><span class="comment"># 3.初始化 logger</span></span><br><span class="line">logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)</span><br><span class="line"><span class="comment"># 4.收集运行环境并且打印，方便排查硬件和软件相关问题</span></span><br><span class="line">env_info_dict = collect_env()</span><br><span class="line"><span class="comment"># 5.初始化 model</span></span><br><span class="line">model = build_detector(cfg.model, ...)</span><br><span class="line"><span class="comment"># 6.初始化 datasets</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#=================== mmdet/apis/train.py ==================</span></span><br><span class="line"><span class="comment"># 1.初始化 data_loaders ，内部会初始化 GroupSampler</span></span><br><span class="line">data_loader = DataLoader(dataset,...)</span><br><span class="line"><span class="comment"># 2.基于是否使用分布式训练，初始化对应的 DataParallel</span></span><br><span class="line"><span class="keyword">if</span> distributed:</span><br><span class="line">  model = MMDistributedDataParallel(...)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">  model = MMDataParallel(...)</span><br><span class="line"><span class="comment"># 3.初始化 runner</span></span><br><span class="line">runner = EpochBasedRunner(...)</span><br><span class="line"><span class="comment"># 4.注册必备 hook</span></span><br><span class="line">runner.register_training_hooks(cfg.lr_config, optimizer_config,</span><br><span class="line">                               cfg.checkpoint_config, cfg.log_config,</span><br><span class="line">                               cfg.get(<span class="string">&#x27;momentum_config&#x27;</span>, <span class="literal">None</span>))</span><br><span class="line"><span class="comment"># 5.如果需要 val，则还需要注册 EvalHook           </span></span><br><span class="line">runner.register_hook(eval_hook(val_dataloader, **eval_cfg))</span><br><span class="line"><span class="comment"># 6.注册用户自定义 hook</span></span><br><span class="line">runner.register_hook(hook, priority=priority)</span><br><span class="line"><span class="comment"># 7.权重恢复和加载</span></span><br><span class="line"><span class="keyword">if</span> cfg.resume_from:</span><br><span class="line">    runner.resume(cfg.resume_from)</span><br><span class="line"><span class="keyword">elif</span> cfg.load_from:</span><br><span class="line">    runner.load_checkpoint(cfg.load_from)</span><br><span class="line"><span class="comment"># 8.运行，开始训练</span></span><br><span class="line">runner.run(data_loaders, cfg.workflow, cfg.total_epochs)</span><br></pre></td></tr></table></figure>

<p>Runner训练和验证代码抽象<br>runner 对象内部的 run 方式是一个通用方法，可以运行任何 workflow，目前常用的主要是 train 和 val。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, data_loader, **kwargs</span>):</span><br><span class="line">    self.model.train()</span><br><span class="line">    self.mode = <span class="string">&#x27;train&#x27;</span></span><br><span class="line">    self.data_loader = data_loader</span><br><span class="line">    self.call_hook(<span class="string">&#x27;before_train_epoch&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i, data_batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.data_loader):</span><br><span class="line">        self.call_hook(<span class="string">&#x27;before_train_iter&#x27;</span>)</span><br><span class="line">        self.run_iter(data_batch, train_mode=<span class="literal">True</span>)</span><br><span class="line">        self.call_hook(<span class="string">&#x27;after_train_iter&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    self.call_hook(<span class="string">&#x27;after_train_epoch&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">val</span>(<span class="params">self, data_loader, **kwargs</span>):</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line"><span class="comment">#核心函数实际上是 self.run_iter()，如下：</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_iter</span>(<span class="params">self, data_batch, train_mode, **kwargs</span>):</span><br><span class="line">    <span class="keyword">if</span> train_mode:</span><br><span class="line">        <span class="comment"># 对于每次迭代，最终是调用如下函数</span></span><br><span class="line">        outputs = self.model.train_step(data_batch,...)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 对于每次迭代，最终是调用如下函数</span></span><br><span class="line">        outputs = self.model.val_step(data_batch,...)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;log_vars&#x27;</span> <span class="keyword">in</span> outputs:</span><br><span class="line">        self.log_buffer.update(outputs[<span class="string">&#x27;log_vars&#x27;</span>],...)</span><br><span class="line">    self.outputs = outputs</span><br><span class="line"></span><br><span class="line"><span class="comment">#上述 self.call_hook() 表示在不同生命周期调用所有已经注册进去的 hook，而字符串参数表示对应的生命周期。以 OptimizerHook 为例，其执行反向传播、梯度裁剪和参数更新等核心训练功能：</span></span><br><span class="line"><span class="meta">@HOOKS.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OptimizerHook</span>(<span class="title class_ inherited__">Hook</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, grad_clip=<span class="literal">None</span></span>):</span><br><span class="line">        self.grad_clip = grad_clip</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">after_train_iter</span>(<span class="params">self, runner</span>):</span><br><span class="line">        runner.optimizer.zero_grad()</span><br><span class="line">        runner.outputs[<span class="string">&#x27;loss&#x27;</span>].backward()</span><br><span class="line">        <span class="keyword">if</span> self.grad_clip <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            grad_norm = self.clip_grads(runner.model.parameters())</span><br><span class="line">        runner.optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="comment">#可以发现 OptimizerHook 注册到的生命周期是 after_train_iter，故在每次 train() 里面运行到self.call_hook(&#x27;after_train_iter&#x27;) 时候就会被调用，其他 hook 也是同样运行逻辑。</span></span><br></pre></td></tr></table></figure>

<p>Model 训练和测试代码抽象<br>训练和验证的时候实际上调用了 model 内部的 train_step 和 val_step 函数，理解了两个函数调用流程就理解了 MMDetection 训练和测试流程。<br>由于 model 对象会被 DataParallel 类包裹，故实际上上此时的 model，是指的 MMDataParallel, 以train_step 流程为例，其内部完成调用流程图示如下：<br><img data-src="https://pic4.zhimg.com/80/v2-0d17b53f68286931803bf9d1dca10467_1440w.webp" alt="train_step"></p>
<h3 id="Head流程"><a href="#Head流程" class="headerlink" title="Head流程"></a><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/343433169">Head流程</a></h3><p><img data-src="https://pic4.zhimg.com/80/v2-ba9edb24f8cbf10ee77bacb7f10befa7_1440w.webp" alt="Head"></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#============= mmdet/models/detectors/single_stage.py/SingleStageDetector ============</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward_train</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="built_in">super</span>(SingleStageDetector, self).forward_train(img, img_metas)</span><br><span class="line">    <span class="comment"># 先进行 backbone+neck 的特征提取</span></span><br><span class="line">    x = self.extract_feat(img)</span><br><span class="line">    <span class="comment"># 主要是调用 bbox_head 内部的 forward_train 方法</span></span><br><span class="line">    losses = self.bbox_head.forward_train(x, ...)</span><br><span class="line">    <span class="keyword">return</span> losses</span><br></pre></td></tr></table></figure>
<p>读起来有点吃力，后续结合源码读</p>
<h2 id="修改"><a href="#修改" class="headerlink" title="修改"></a>修改</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">│</span><br><span class="line">├───configs</span><br><span class="line">│   └───FedPSD</span><br><span class="line">│           yolo.py</span><br><span class="line">│</span><br><span class="line">├───mmdet</span><br><span class="line">│   ├───datasets</span><br><span class="line">│   │   │   markingpoint.py</span><br><span class="line">│   │   │   __init__.py</span><br><span class="line">│   │   │</span><br><span class="line">│   │   └───pipelines   <span class="comment">#pipeline似乎可以复用，在配置文件里改？</span></span><br><span class="line">│   │       │   formating.py    </span><br><span class="line">│   │       │   loading.py  <span class="comment">#数据加载</span></span><br><span class="line">│   │       │   transforms.py   <span class="comment">#数据处理</span></span><br><span class="line">│   │       └───__init__.py</span><br><span class="line">│   │</span><br><span class="line">│   └───models</span><br><span class="line">│       ├───dense_heads</span><br><span class="line">│       │   │   psd_head.py</span><br><span class="line">│       │   └───__init__.py</span><br><span class="line">│       │</span><br><span class="line">│       └───detectors</span><br><span class="line">│           │   parking_slot_det.py</span><br><span class="line">│           └───__init__.py</span><br></pre></td></tr></table></figure>
<p>在修改之后，需要重新编译mmdet,在根目录使用<br><code>python setup.py install</code> <code>pip install -v -e .</code>, 否则会报错</p>
<h2 id="notes"><a href="#notes" class="headerlink" title="notes"></a>notes</h2><ul>
<li><code>@TRANSFORMS.register_module()</code><br>这是 MMDetection 库提供的一个 Python 装饰器。它用于将一个新的模块（通常是一个定义数据增强或预处理操作的类）注册到 MMDetection 库的流水线系统中。位于一个类定义的上方。<br>TRANSFORMS: 这是 MMDetection 中的一个注册表，用于存储目标检测流水线中使用的不同数据增强和预处理步骤。<br>register_module(): 这是 TRANSFORMS 注册表中的一个函数，用于注册一个新的模块。</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/Embedded/" rel="prev" title="Embedded：嵌入式应用知识">
      <i class="fa fa-chevron-left"></i> Embedded：嵌入式应用知识
    </a></div>
      <div class="post-nav-item">
    <a href="/Project/" rel="next" title="Project：多个项目汇总">
      Project：多个项目汇总 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6"><span class="nav-number">1.</span> <span class="nav-text">深度学习框架</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0-Activate-Function"><span class="nav-number">1.1.</span> <span class="nav-text">激活函数 Activate Function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%84%9F%E5%8F%97%E9%87%8E-Receptive-field"><span class="nav-number">1.2.</span> <span class="nav-text">感受野(Receptive field)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF"><span class="nav-number">1.3.</span> <span class="nav-text">卷积</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-number">1.4.</span> <span class="nav-text">反向传播</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Optimizer"><span class="nav-number">1.5.</span> <span class="nav-text">Optimizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Batch-size"><span class="nav-number">1.6.</span> <span class="nav-text">Batch size</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E3%80%8Closs-function%E3%80%8D"><span class="nav-number">1.7.</span> <span class="nav-text">损失函数「loss function」</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">1.7.1.</span> <span class="nav-text">基于距离度量的损失函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%E5%BA%A6%E9%87%8F%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">1.7.2.</span> <span class="nav-text">基于概率分布度量的损失函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%88Attention-Mechanism%EF%BC%89"><span class="nav-number">2.</span> <span class="nav-text">注意力机制（Attention Mechanism）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BD%AF%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%9F%9F"><span class="nav-number">2.1.</span> <span class="nav-text">软注意力的注意力域</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A9%BA%E9%97%B4%E5%9F%9F%EF%BC%88Spatial-Domain%EF%BC%89"><span class="nav-number">2.1.1.</span> <span class="nav-text">空间域（Spatial Domain）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%9A%E9%81%93%E5%9F%9F%EF%BC%88Channel-Domain%EF%BC%89"><span class="nav-number">2.1.2.</span> <span class="nav-text">通道域（Channel Domain）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%B6%E5%9F%9F%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="nav-number">2.1.3.</span> <span class="nav-text">时域注意力机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%9A%E9%81%93%E5%92%8C%E7%A9%BA%E9%97%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="nav-number">2.1.4.</span> <span class="nav-text">通道和空间注意力机制</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Metrics-%E8%AF%84%E4%BC%B0"><span class="nav-number">3.</span> <span class="nav-text">Metrics 评估</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5"><span class="nav-number">3.1.</span> <span class="nav-text">混淆矩阵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Evaluation-parameters"><span class="nav-number">3.2.</span> <span class="nav-text">Evaluation parameters</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%A1%E7%AE%97%E9%87%8F-FLOPs-%E5%92%8C%E5%8F%82%E6%95%B0%E9%87%8F-Params"><span class="nav-number">3.3.</span> <span class="nav-text">模型计算量(FLOPs)和参数量(Params)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Transformer"><span class="nav-number">4.</span> <span class="nav-text">Transformer</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5"><span class="nav-number">5.</span> <span class="nav-text">相关概念</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0"><span class="nav-number">5.1.</span> <span class="nav-text">联邦学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83"><span class="nav-number">5.2.</span> <span class="nav-text">分布式训练</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MMDetection"><span class="nav-number">6.</span> <span class="nav-text">MMDetection</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">6.1.</span> <span class="nav-text">配置文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B"><span class="nav-number">6.2.</span> <span class="nav-text">进阶教程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E7%BB%84%E4%BB%B6%EF%BC%9A"><span class="nav-number">6.2.1.</span> <span class="nav-text">算法组件：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B4%E4%BD%93%E6%9E%84%E5%BB%BA%E7%BB%86%E8%8A%82"><span class="nav-number">6.2.2.</span> <span class="nav-text">整体构建细节</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Head%E6%B5%81%E7%A8%8B"><span class="nav-number">6.2.3.</span> <span class="nav-text">Head流程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9"><span class="nav-number">6.3.</span> <span class="nav-text">修改</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#notes"><span class="nav-number">6.4.</span> <span class="nav-text">notes</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Arrow</p>
  <div class="site-description" itemprop="description">记录一些杂七杂八的东西</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Arrowes" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Arrowes" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:395841716@qq.com" title="E-Mail → mailto:395841716@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/wangyujie.site" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;wangyujie.site" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>Zhihu</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/Arrowes?spm=1000.2115.3001.5343" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;Arrowes?spm&#x3D;1000.2115.3001.5343" rel="noopener" target="_blank"><i class="fa fa-crosshairs fa-fw"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/23930762?spm_id_from=333.1007.0.0" title="bilibili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;23930762?spm_id_from&#x3D;333.1007.0.0" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>bilibili</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://oshwhub.com/arrows" title="立创EDA → https:&#x2F;&#x2F;oshwhub.com&#x2F;arrows" rel="noopener" target="_blank"><i class="fa fa-microchip fa-fw"></i>立创EDA</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Arrow</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">93k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">5:39</span>
</div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-pjax@0/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  
  <script data-pjax>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="/js/local-search.js"></script>











<script data-pjax>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'dark',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '0cf14e51c1582cf64289',
      clientSecret: '5e8273d27714e40495267c73e607cfe9322b7266',
      repo        : 'Arrowes.github.io',
      owner       : 'Arrowes',
      admin       : ['Arrowes'],
      id          : 'f87a6dc1598ca3bb138b91c5c98341e7',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

    </div>
</body>
</html>
